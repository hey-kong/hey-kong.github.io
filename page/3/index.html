<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Iggie Wang&#039;s Cyberspace</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Iggie Wang&#039;s Cyberspace"><meta name="msapplication-TileImage" content="/img/dog.jpg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Iggie Wang&#039;s Cyberspace"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="Iggie Wang&#039;s Cyberspace"><meta property="og:url" content="https://hey-kong.github.io/"><meta property="og:site_name" content="Iggie Wang&#039;s Cyberspace"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://hey-kong.github.io/img/og_image.png"><meta property="article:author" content="王亮"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://hey-kong.github.io"},"headline":"Iggie Wang's Cyberspace","image":["https://hey-kong.github.io/img/og_image.png"],"author":{"@type":"Person","name":"王亮"},"publisher":{"@type":"Organization","name":"Iggie Wang's Cyberspace","logo":{"@type":"ImageObject","url":null}},"description":""}</script><link rel="icon" href="/img/dog.jpg"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.15.2/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/cookieconsent/3.1.1/cookieconsent.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/pace/1.0.2/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.3.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">Iggie Wang&#039;s Cyberspace</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/2021/01/16/About-me">About</a></div><div class="navbar-end"><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2021-05-06T06:03:34.000Z" title="2021-5-6 14:03:34">2021-05-06</time>发表</span><span class="level-item">11 分钟读完 (大约1575个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/05/06/WiscKey-Separating-Keys-from-Values-in-SSD-conscious-Storage/">WiscKey: Separating Keys from Values in SSD-conscious Storage</a></h1><div class="content"><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><h3 id="读写放大"><a href="#读写放大" class="headerlink" title="读写放大"></a>读写放大</h3><p>LSM-Tree key-value 存储存在读写放大的问题，例如对于LevelDB来说：</p>
<ul>
<li><p>写放大：假如每一层的大小是上一层的 10 倍，那么当把 i-1 层中的一个文件合并到 i 层中时，LevelDB 需要读取 i 层中的文件的数量多达 10 个，排序后再将他们写回到 i 层中去。所以这个时候的写放大是 10。对于一个很大的数据集，生成一个新的 SSTable 文件可能会导致 L0-L6 中相邻层之间发生合并操作，这个时候的写放大就是50（L1-L6中每一层是10）。</p>
</li>
<li><p>读放大：(1) 查找一个 key-value 对时，LevelDB 可能需要在多个层中去查找。在最坏的情况下，LevelDB 在 L0 中需要查找 8 个文件，在 L1-L6 每层中需要查找 1 个文件，累计就需要查找 14 个文件。(2) 在一个 SSTable 文件中查找一个 key-value 对时，LevelDB 需要读取该文件的多个元数据块。所以实际读取的数据量应该是：<code>index block + bloom-filter blocks + data block</code>。例如，当查找 1KB 的 key-value 对时，LevelDB 需要读取 16KB 的 index block，4KB的 bloom-filter block 和 4KB 的 data block，总共要读取 24 KB 的数据。在最差的情况下需要读取 14 个 SSTable 文件，所以这个时候的写放大就是 24*14=336。较小的 key-value 对会带来更高的读放大。</p>
</li>
</ul>
<p>WiscKey 论文中针对 LevelDB 测试的读写放大数据：</p>
<div align="center">
<img src="/2021/05/06/WiscKey-Separating-Keys-from-Values-in-SSD-conscious-Storage/1.png" style="zoom:100%;">
</div>

<h3 id="存储硬件"><a href="#存储硬件" class="headerlink" title="存储硬件"></a>存储硬件</h3><p>在 SSD 上，顺序和随机读写性能差异不大。对于写操作而言，由于随机写会对 SSD 的寿命造成影响，顺序写的特性应该保留，对于读操作来说，顺序读和随机读的性能测试如下图所示：</p>
<div align="center">
<img src="/2021/05/06/WiscKey-Separating-Keys-from-Values-in-SSD-conscious-Storage/2.png" style="zoom:100%;">
</div>

<p>每次请求数据的 size 越大，SSD 的随机读与顺序读差距越小，并发数越大，SSD 的随机读与顺序读差距也越小。</p>
<h2 id="WiscKey"><a href="#WiscKey" class="headerlink" title="WiscKey"></a>WiscKey</h2><p>WiscKey 包括四个关键思想：</p>
<p>(1) KV 分离，只有 key 在 LSM-Tree 上。<br>(2) 在 KV 分离后，value 采用顺序追加写，不保序。因此范围查询中，WiscKey 使用并行 SSD 设备的随机读特性查询 value。<br>(3) 使用 crash-consistency 和 garbage-collection 有效管理 value log。<br>(4) 通过删除 LSM-Tree 日志而不牺牲一致性来优化性能。</p>
<h3 id="KV-分离"><a href="#KV-分离" class="headerlink" title="KV 分离"></a>KV 分离</h3><div align="center">
<img src="/2021/05/06/WiscKey-Separating-Keys-from-Values-in-SSD-conscious-Storage/3.png" style="zoom:100%;">
</div>

<p>KV 分离的设计要点如下：</p>
<ul>
<li>key 存在 LSM-Tree 上。</li>
<li>value 存在单独的 value log 中。</li>
<li>插入/更新数据的时候，首先将 value 追加到value log，然后将 key 插入 LSM-Tree 中。</li>
<li>删除数据的时候，只是将 key 在 LSM-Tree 中删除，value log 的数据不需要改变，因为 WiscKey 会有垃圾回收机制处理对应的 value。</li>
<li>读取数据时，先读 LSM-Tree，然后读 value log。</li>
</ul>
<h3 id="KV-分离对应的-Challenges"><a href="#KV-分离对应的-Challenges" class="headerlink" title="KV 分离对应的 Challenges"></a>KV 分离对应的 Challenges</h3><h4 id="Parallel-Range-Query"><a href="#Parallel-Range-Query" class="headerlink" title="Parallel Range Query"></a>Parallel Range Query</h4><ol>
<li>范围查询时，WiscKey 从 LSM-Tree 中读取多个 key 的元数据信息 &lt;key, address&gt;。</li>
<li>将这些 &lt;key, address&gt; 放入队列。</li>
<li>预读线程（默认32个）会从队列中获取 value 的地址，然后并行读取 value 数据。</li>
</ol>
<h4 id="Garbage-Collection"><a href="#Garbage-Collection" class="headerlink" title="Garbage Collection"></a>Garbage Collection</h4><div align="center">
<img src="/2021/05/06/WiscKey-Separating-Keys-from-Values-in-SSD-conscious-Storage/4.png" style="zoom:100%;">
</div>

<p>Value log 结构如图所示，其由 value_entry 组成，每个value_entry 是一个四元组 <code>(key size, value size, key, value)</code>。另外，Value log 有两个指针 head 和 tail，tail 指向 Value log 的起点；head 指向文件的尾部，所有新的数据都将追加到 head 位置。</p>
<p>垃圾回收时，线程将从 tail 指向的位置开始，每次读取一个 chunk 的数据（比如几MB），对于 chunk 中的每一个 value_entry，在 LSM-Tree 中查找 key 以便判断该 value_entry 是否仍然有效。如果有效，则将该条目追加到 head 指针指向的位置，并且需要更新 LSM-Tree 的记录，因为 value 的地址已经变了；如果无效，则将其舍弃。</p>
<p>同时，为了避免出现数据不一致（如在垃圾回收过程中发生了 crash），需要保证在释放对应的存储空间之前追加写入的新的有效 value 和新的 tail 指针持久化到了设备上。具体的步骤如下：</p>
<ul>
<li>垃圾回收在将 value 追加到 vLog 之后，在 vLog 上调用 fsync()</li>
<li>同步地将新的 value 地址和 tail 指针地址写入到 LSM-Tree 中。（tail 指针的存储形式为 <code>&lt;‘‘tail’’, tail-vLog-offset&gt;</code>）</li>
<li>最后回收 vLog 旧的数据空间</li>
</ul>
<h4 id="Crash-Consistency"><a href="#Crash-Consistency" class="headerlink" title="Crash Consistency"></a>Crash Consistency</h4><ol>
<li>如果不能在 LSM-Tree 中查询到对应的 key，那么处理方式和传统的 LSM-Tree 一样，返回空或者 key 不存在，即便其 value 已经写入到了 vLog 文件中，也会对其进行垃圾回收。</li>
<li>如果 LSM-Tree 中存在要查询的 Key，则会进行校验。校验首先校验从 LSM-Tree 中查询到的 value 地址信息是否在有效的 vLog 文件范围内；其次校验该地址对应的 value 上存取的 key 和要查询的 key 是否一致。如果校验失败，则删除 LSM-Tree 中相应 key，并返回 key 不存在。</li>
<li>另外，还可以引入 magic number 或 checksum 来校验 key 和 value 是否匹配。</li>
</ol>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>WiscKey 基于 LevelDB，设计了一个针对 SSD 进行优化的持久化 KV 存储方案，它的核心思想就是将 key 和 value 分离，key 存储在 LSM-Tree 中，value 存储在 value log 中，保留了 LSM-Tree 的优势，减少读写放大，发挥了 SSD 顺序写与并行随机读性能好的优势，但在小 value 场景以及大数据集范围查询下，WiscKey 的性能比 LevelDB 差。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li>Lu L, Pillai T S, Arpaci-Dusseau A C, et al. WiscKey: separating keys from values in SSD-conscious storage[C] 14th USENIX Conference on File and Storage Technologies (FAST 16). 2016: 133-148.</li>
<li><a target="_blank" rel="noopener" href="http://cighao.com/2016/08/13/leveldb-source-analysis-01-introduction/">LevelDB 源码分析（一）：简介</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/30953751">WiscKey: Separating Keys from Values in SSD-conscious Storage</a></li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2021-04-05T08:33:37.000Z" title="2021-4-5 16:33:37">2021-04-05</time>发表</span><span class="level-item">16 分钟读完 (大约2329个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/04/05/RocksDB-WriteImpl-%E6%B5%81%E7%A8%8B/">RocksDB WriteImpl 流程</a></h1><div class="content"><p><code>本文对 RocksDB 6.7.3 版本的 WriteImpl 流程进行分析。</code></p>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>RocksDB 写入实现主要在 DBImpl::WriteImpl 中，过程主要分为以下三步：</p>
<ul>
<li>把 WriteBatch 加入队列，多个 WriteBatch 成为一个 WriteGroup</li>
<li>将该 WriteGroup 所有的记录对应的日志写到 WAL 文件中</li>
<li>将该 WriteGroup 所有的 WriteBatch 中的一条或者多条记录写到内存中的 Memtable 中</li>
</ul>
<p>其中，每个 WriteBatch 代表一个事务的提交，可以包含多条操作，可以通过调用 WriteBatch::Put/Delete 等操作将对应多条的 key/value 记录加入 WriteBatch 中。</p>
<h2 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h2><h3 id="WriteThread-JoinBatchGroup"><a href="#WriteThread-JoinBatchGroup" class="headerlink" title="WriteThread::JoinBatchGroup"></a>WriteThread::JoinBatchGroup</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">static WriteThread::AdaptationContext jbg_ctx(<span class="string">&quot;JoinBatchGroup&quot;</span>);</span><br><span class="line">void WriteThread::JoinBatchGroup(Writer* w) &#123;</span><br><span class="line">  TEST_SYNC_POINT_CALLBACK(<span class="string">&quot;WriteThread::JoinBatchGroup:Start&quot;</span>, w);</span><br><span class="line">  assert(w-&gt;batch != nullptr);</span><br><span class="line"></span><br><span class="line">  bool linked_as_leader = LinkOne(w, &amp;newest_writer_);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (linked_as_leader) &#123;</span><br><span class="line">    SetState(w, STATE_GROUP_LEADER);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  TEST_SYNC_POINT_CALLBACK(<span class="string">&quot;WriteThread::JoinBatchGroup:Wait&quot;</span>, w);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (!linked_as_leader) &#123;</span><br><span class="line">    /**</span><br><span class="line">     * Wait util:</span><br><span class="line">     * 1) An existing leader pick us as the new leader when it finishes</span><br><span class="line">     * 2) An existing leader pick us as its follewer and</span><br><span class="line">     * 2.1) finishes the memtable writes on our behalf</span><br><span class="line">     * 2.2) Or tell us to finish the memtable writes <span class="keyword">in</span> pralallel</span><br><span class="line">     * 3) (pipelined write) An existing leader pick us as its follower and</span><br><span class="line">     *    finish book-keeping and WAL write <span class="keyword">for</span> us, enqueue us as pending</span><br><span class="line">     *    memtable writer, and</span><br><span class="line">     * 3.1) we become memtable writer group leader, or</span><br><span class="line">     * 3.2) an existing memtable writer group leader tell us to finish memtable</span><br><span class="line">     *      writes <span class="keyword">in</span> parallel.</span><br><span class="line">     */</span><br><span class="line">    TEST_SYNC_POINT_CALLBACK(<span class="string">&quot;WriteThread::JoinBatchGroup:BeganWaiting&quot;</span>, w);</span><br><span class="line">    AwaitState(w, STATE_GROUP_LEADER | STATE_MEMTABLE_WRITER_LEADER |</span><br><span class="line">                      STATE_PARALLEL_MEMTABLE_WRITER | STATE_COMPLETED,</span><br><span class="line">               &amp;jbg_ctx);</span><br><span class="line">    TEST_SYNC_POINT_CALLBACK(<span class="string">&quot;WriteThread::JoinBatchGroup:DoneWaiting&quot;</span>, w);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>每个事务提交请求都会生成一个 WriteBatch 对象，进入 WriteImpl 函数后各自的线程首先调用 JoinBatchGroup 来加入到队列。该队列主要核心的实现在于 LinkOne 函数，通过 CAS 无锁将多个线程的请求组成请求链表：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">bool WriteThread::LinkOne(Writer* w, std::atomic&lt;Writer*&gt;* newest_writer) &#123;</span><br><span class="line">  assert(newest_writer != nullptr);</span><br><span class="line">  assert(w-&gt;state == STATE_INIT);</span><br><span class="line">  Writer* writers = newest_writer-&gt;load(std::memory_order_relaxed);</span><br><span class="line">  <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">    // If write stall <span class="keyword">in</span> effect, and w-&gt;no_slowdown is not <span class="literal">true</span>,</span><br><span class="line">    // block here until stall is cleared. If its <span class="literal">true</span>, <span class="keyword">then</span> <span class="built_in">return</span></span><br><span class="line">    // immediately</span><br><span class="line">    <span class="keyword">if</span> (writers == &amp;write_stall_dummy_) &#123;</span><br><span class="line">      <span class="keyword">if</span> (w-&gt;no_slowdown) &#123;</span><br><span class="line">        w-&gt;status = Status::Incomplete(<span class="string">&quot;Write stall&quot;</span>);</span><br><span class="line">        SetState(w, STATE_COMPLETED);</span><br><span class="line">        <span class="built_in">return</span> <span class="literal">false</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      // Since no_slowdown is <span class="literal">false</span>, <span class="built_in">wait</span> here to be notified of the write</span><br><span class="line">      // stall clearing</span><br><span class="line">      &#123;</span><br><span class="line">        MutexLock lock(&amp;stall_mu_);</span><br><span class="line">        writers = newest_writer-&gt;load(std::memory_order_relaxed);</span><br><span class="line">        <span class="keyword">if</span> (writers == &amp;write_stall_dummy_) &#123;</span><br><span class="line">          stall_cv_.Wait();</span><br><span class="line">          // Load newest_writers_ again since it may have changed</span><br><span class="line">          writers = newest_writer-&gt;load(std::memory_order_relaxed);</span><br><span class="line">          <span class="built_in">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    w-&gt;link_older = writers;</span><br><span class="line">    <span class="keyword">if</span> (newest_writer-&gt;compare_exchange_weak(writers, w)) &#123;</span><br><span class="line">      <span class="built_in">return</span> (writers == nullptr);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>write_group 链表结构如下：</p>
<img src="/2021/04/05/RocksDB-WriteImpl-%E6%B5%81%E7%A8%8B/write_group.png" style="zoom:100%;">

<p>每个 writer 在头部插入，插入时如果发现 link_older 为空，则此 writer 成为 write_group 的 Leader（即链表尾为 Leader）。</p>
<p>在 JoinBatchGroup 中，如果 writer 不是 Leader（在后文把不是 Leader 的 writer 称为 Follower），则会调用 AwaitState 等待被唤醒。</p>
<blockquote>
<p>PS：由于条件锁 Context Switches 代价高，Rocksdb 在 AwaitState 也做了优化，将 pthread_cond_wait 拆成 3 步来做，本文不对该优化进行详细描述。</p>
</blockquote>
<h3 id="WriteImpl-写日志"><a href="#WriteImpl-写日志" class="headerlink" title="WriteImpl 写日志"></a>WriteImpl 写日志</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (w.state == WriteThread::STATE_GROUP_LEADER) &#123;</span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">  last_batch_group_size_ =</span><br><span class="line">      write_thread_.EnterAsBatchGroupLeader(&amp;w, &amp;wal_write_group);</span><br><span class="line">  const SequenceNumber current_sequence =</span><br><span class="line">      write_thread_.UpdateLastSequence(versions_-&gt;LastSequence()) + 1;</span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (w.status.ok() &amp;&amp; !write_options.disableWAL) &#123;</span><br><span class="line">    PERF_TIMER_GUARD(write_wal_time);</span><br><span class="line">    stats-&gt;AddDBStats(InternalStats::kIntStatsWriteDoneBySelf, 1);</span><br><span class="line">    RecordTick(stats_, WRITE_DONE_BY_SELF, 1);</span><br><span class="line">    <span class="keyword">if</span> (wal_write_group.size &gt; 1) &#123;</span><br><span class="line">      stats-&gt;AddDBStats(InternalStats::kIntStatsWriteDoneByOther,</span><br><span class="line">                        wal_write_group.size - 1);</span><br><span class="line">      RecordTick(stats_, WRITE_DONE_BY_OTHER, wal_write_group.size - 1);</span><br><span class="line">    &#125;</span><br><span class="line">    w.status = WriteToWAL(wal_write_group, log_writer, log_used,</span><br><span class="line">                          need_log_sync, need_log_dir_sync, current_sequence);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">  write_thread_.ExitAsBatchGroupLeader(wal_write_group, w.status);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>成为 Leader 的 writer，负责批量写入 WAL。在写 WAL 前，首先调用 EnterAsBatchGroupLeader 函数：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line">size_t WriteThread::EnterAsBatchGroupLeader(Writer* leader,</span><br><span class="line">                                            WriteGroup* write_group) &#123;</span><br><span class="line">  assert(leader-&gt;link_older == nullptr);</span><br><span class="line">  assert(leader-&gt;batch != nullptr);</span><br><span class="line">  assert(write_group != nullptr);</span><br><span class="line"></span><br><span class="line">  size_t size = WriteBatchInternal::ByteSize(leader-&gt;batch);</span><br><span class="line"></span><br><span class="line">  // Allow the group to grow up to a maximum size, but <span class="keyword">if</span> the</span><br><span class="line">  // original write is small, <span class="built_in">limit</span> the growth so we <span class="keyword">do</span> not slow</span><br><span class="line">  // down the small write too much.</span><br><span class="line">  size_t max_size = max_write_batch_group_size_bytes;</span><br><span class="line">  const uint64_t min_batch_size_bytes = max_write_batch_group_size_bytes / 8;</span><br><span class="line">  <span class="keyword">if</span> (size &lt;= min_batch_size_bytes) &#123;</span><br><span class="line">    max_size = size + min_batch_size_bytes;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  leader-&gt;write_group = write_group;</span><br><span class="line">  write_group-&gt;leader = leader;</span><br><span class="line">  write_group-&gt;last_writer = leader;</span><br><span class="line">  write_group-&gt;size = 1;</span><br><span class="line">  Writer* newest_writer = newest_writer_.load(std::memory_order_acquire);</span><br><span class="line"></span><br><span class="line">  // This is safe regardless of any db mutex status of the <span class="built_in">caller</span>. Previous</span><br><span class="line">  // calls to ExitAsGroupLeader either didn<span class="string">&#x27;t call CreateMissingNewerLinks</span></span><br><span class="line"><span class="string">  // (they emptied the list and then we added ourself as leader) or had to</span></span><br><span class="line"><span class="string">  // explicitly wake us up (the list was non-empty when we added ourself,</span></span><br><span class="line"><span class="string">  // so we have already received our MarkJoined).</span></span><br><span class="line"><span class="string">  CreateMissingNewerLinks(newest_writer);</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  // Tricky. Iteration start (leader) is exclusive and finish</span></span><br><span class="line"><span class="string">  // (newest_writer) is inclusive. Iteration goes from old to new.</span></span><br><span class="line"><span class="string">  Writer* w = leader;</span></span><br><span class="line"><span class="string">  while (w != newest_writer) &#123;</span></span><br><span class="line"><span class="string">    w = w-&gt;link_newer;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    if (w-&gt;sync &amp;&amp; !leader-&gt;sync) &#123;</span></span><br><span class="line"><span class="string">      // Do not include a sync write into a batch handled by a non-sync write.</span></span><br><span class="line"><span class="string">      break;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    if (w-&gt;no_slowdown != leader-&gt;no_slowdown) &#123;</span></span><br><span class="line"><span class="string">      // Do not mix writes that are ok with delays with the ones that</span></span><br><span class="line"><span class="string">      // request fail on delays.</span></span><br><span class="line"><span class="string">      break;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    if (w-&gt;disable_wal != leader-&gt;disable_wal) &#123;</span></span><br><span class="line"><span class="string">      // Do not mix writes that enable WAL with the ones whose</span></span><br><span class="line"><span class="string">      // WAL disabled.</span></span><br><span class="line"><span class="string">      break;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    if (w-&gt;batch == nullptr) &#123;</span></span><br><span class="line"><span class="string">      // Do not include those writes with nullptr batch. Those are not writes,</span></span><br><span class="line"><span class="string">      // those are something else. They want to be alone</span></span><br><span class="line"><span class="string">      break;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    if (w-&gt;callback != nullptr &amp;&amp; !w-&gt;callback-&gt;AllowWriteBatching()) &#123;</span></span><br><span class="line"><span class="string">      // dont batch writes that don&#x27;</span>t want to be batched</span><br><span class="line">      <span class="built_in">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    auto batch_size = WriteBatchInternal::ByteSize(w-&gt;batch);</span><br><span class="line">    <span class="keyword">if</span> (size + batch_size &gt; max_size) &#123;</span><br><span class="line">      // Do not make batch too big</span><br><span class="line">      <span class="built_in">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    w-&gt;write_group = write_group;</span><br><span class="line">    size += batch_size;</span><br><span class="line">    write_group-&gt;last_writer = w;</span><br><span class="line">    write_group-&gt;size++;</span><br><span class="line">  &#125;</span><br><span class="line">  TEST_SYNC_POINT_CALLBACK(<span class="string">&quot;WriteThread::EnterAsBatchGroupLeader:End&quot;</span>, w);</span><br><span class="line">  <span class="built_in">return</span> size;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在这里，通过 CreateMissingNewerLinks 函数来生成一个双向链表，使得可以从 Leader 开始顺序写。创建完成反向写请求链表之后，则开始计算有多少个写请求可以批量的进行，同时更新 write_group 中的批量写尺寸以及个数等信息，EnterAsBatchGroupLeader 取队列时会把此刻所有的 writer 一次性全取完。</p>
<p>该操作完成之后，则进入写 WAL 的流程了。调用 WriteToWAL，在 MergeBatch 函数中，将根据 write_group 生成一个 merged_batch，该 merged_batch 中记录着应当被写入 WAL 的内容。接着就通过 WriteToWAL 将 merged_batch 写入 WAL 中，这里会根据是否设置了 sync 来决定是否对 WAL 进行落盘操作。</p>
<blockquote>
<p>PS：这里有一个优化点，在生成 merged_batch 的时候，假设该写请求的尺寸为一并且该请求需要写 WAL，则 merged_batch 直接复用了该写请求；反之则会复用一个 tmp_batch_ 对象避免频繁的生成 WriteBatch 对象。在写完 WAL 之后，假设复用了 tmp_batch_，则会清空该对象。</p>
</blockquote>
<p>最后，调用 ExitAsBatchGroupLeader，该函数会决定该 Leader 是否为 STATE_MEMTABLE_WRITER_LEADER（MEMTABLE_WRITER_LEADER数量 &lt;= GROUP_LEADER数量），从而进行写 Memtable 流程。</p>
<h3 id="WriteImpl-写-Memtable"><a href="#WriteImpl-写-Memtable" class="headerlink" title="WriteImpl 写 Memtable"></a>WriteImpl 写 Memtable</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">WriteThread::WriteGroup memtable_write_group;</span><br><span class="line">  <span class="keyword">if</span> (w.state == WriteThread::STATE_MEMTABLE_WRITER_LEADER) &#123;</span><br><span class="line">    PERF_TIMER_GUARD(write_memtable_time);</span><br><span class="line">    assert(w.ShouldWriteToMemtable());</span><br><span class="line">    write_thread_.EnterAsMemTableWriter(&amp;w, &amp;memtable_write_group);</span><br><span class="line">    <span class="keyword">if</span> (memtable_write_group.size &gt; 1 &amp;&amp;</span><br><span class="line">        immutable_db_options_.allow_concurrent_memtable_write) &#123;</span><br><span class="line">      write_thread_.LaunchParallelMemTableWriters(&amp;memtable_write_group);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      memtable_write_group.status = WriteBatchInternal::InsertInto(</span><br><span class="line">          memtable_write_group, w.sequence, column_family_memtables_.get(),</span><br><span class="line">          &amp;flush_scheduler_, &amp;trim_history_scheduler_,</span><br><span class="line">          write_options.ignore_missing_column_families, 0 /*log_number*/, this,</span><br><span class="line">          <span class="literal">false</span> /*concurrent_memtable_writes*/, seq_per_batch_, batch_per_txn_);</span><br><span class="line">      versions_-&gt;SetLastSequence(memtable_write_group.last_sequence);</span><br><span class="line">      write_thread_.ExitAsMemTableWriter(&amp;w, memtable_write_group);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (w.state == WriteThread::STATE_PARALLEL_MEMTABLE_WRITER) &#123;</span><br><span class="line">    assert(w.ShouldWriteToMemtable());</span><br><span class="line">    ColumnFamilyMemTablesImpl column_family_memtables(</span><br><span class="line">        versions_-&gt;GetColumnFamilySet());</span><br><span class="line">    w.status = WriteBatchInternal::InsertInto(</span><br><span class="line">        &amp;w, w.sequence, &amp;column_family_memtables, &amp;flush_scheduler_,</span><br><span class="line">        &amp;trim_history_scheduler_, write_options.ignore_missing_column_families,</span><br><span class="line">        0 /*log_number*/, this, <span class="literal">true</span> /*concurrent_memtable_writes*/,</span><br><span class="line">        <span class="literal">false</span> /*seq_per_batch*/, 0 /*batch_cnt*/, <span class="literal">true</span> /*batch_per_txn*/,</span><br><span class="line">        write_options.memtable_insert_hint_per_batch);</span><br><span class="line">    <span class="keyword">if</span> (write_thread_.CompleteParallelMemTableWriter(&amp;w)) &#123;</span><br><span class="line">      MemTableInsertStatusCheck(w.status);</span><br><span class="line">      versions_-&gt;SetLastSequence(w.write_group-&gt;last_sequence);</span><br><span class="line">      write_thread_.ExitAsMemTableWriter(&amp;w, *w.write_group);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>RocksDB 有一个 allow_concurrent_memtable_write 的配置项，开启后可以并发写 memtable（memtable 能设置并发写，但是 WAL 文件不能，因为 WAL 是一个追加写的文件，多个 writer 必须要串行化），所以接下来分为串行写和并行写来进行分析。</p>
<h4 id="串行写-Memtable"><a href="#串行写-Memtable" class="headerlink" title="串行写 Memtable"></a>串行写 Memtable</h4><p>Leader 调用 InsertInto，对 write_group 进行遍历，将 Leader 和 Follower 的 WriteBatch 写入。之后调用 ExitAsMemTableWriter，把所有 Follower 的状态设置为 STATE_COMPLETED，将它们唤醒，最后再把 Leader 的状态设置为 STATE_COMPLETED。</p>
<h4 id="并行写-Memtable"><a href="#并行写-Memtable" class="headerlink" title="并行写 Memtable"></a>并行写 Memtable</h4><p>调用 LaunchParallelMemTableWriters，遍历 write_group 把 Leader 和 Follower 的状态都设置为 STATE_PARALLEL_MEMTABLE_WRITER，将等待的线程唤醒。最后所有 writer 通过调用 InsertInto 来将 WriteBatch 写入 MemTable 中。writer 完成了 MemTable 的写操作之后，都会调用 CompleteParallelMemTableWriter 函数。该函数会将该 write_group 中运行的任务数减一，当运行中的任务数为零的时候就代表了所有的线程都完成了操作，调用 ExitAsMemTableWriter 把 Leader 的状态设置为 STATE_COMPLETED，反之则会进入等待状态，等待当前其他的写任务完成。</p>
<p>无论是串行写还是并行写，写入 MemTable 完成之后，还有一项工作，就是在取队列时获取 newest_writer_ 和当前时间点处，可能又有很多的写请求产生了，所以批量任务中最后一个完成的线程必须负责重新指定 Leader 给堆积写请求链表的尾部，让其接过 Leader 角色继续进行批量提交。可以看到，串行写和并行写最后都会调用 ExitAsMemTableWriter，正是在该函数中完成了该项工作。</p>
<blockquote>
<p>PS：在高并发场景下，Follow 调用 AwaitState 的平均等待时延差不多是写 WAL 时延的两倍。因为获取 newest_writer_ 后，可能又来了许多写请求，这些写请求先要等待此时的 Leader 完成写流程，还要等待下个 Leader，也就是和这些写请求是同一个 write_group 的 Leader 完成写 WAL 才能被唤醒。</p>
</blockquote>
<h2 id="回顾"><a href="#回顾" class="headerlink" title="回顾"></a>回顾</h2><img src="/2021/04/05/RocksDB-WriteImpl-%E6%B5%81%E7%A8%8B/rocksdb_write.jpg" style="zoom:100%;">

<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><a target="_blank" rel="noopener" href="https://github.com/facebook/rocksdb/tree/v6.7.3">Rocksdb Source Code 6.7.3</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_43479736/article/details/109056437">rocksdb写流程DBImpl::WriteImpl()源代码分析</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/161797527">RocksDB写入流程</a></li>
<li><a target="_blank" rel="noopener" href="https://gocode.cc/project/13/article/183">RocksDB 写流程分析</a></li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2021-03-28T07:45:42.000Z" title="2021-3-28 15:45:42">2021-03-28</time>发表</span><span class="level-item">13 分钟读完 (大约1977个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/03/28/Vectorization-vs-Compilation-in-Query-Execution/">Vectorization vs. Compilation in Query Execution</a></h1><div class="content"><h2 id="当代-CPU-特性"><a href="#当代-CPU-特性" class="headerlink" title="当代 CPU 特性"></a>当代 CPU 特性</h2><h3 id="超标量流水线与乱序执行"><a href="#超标量流水线与乱序执行" class="headerlink" title="超标量流水线与乱序执行"></a>超标量流水线与乱序执行</h3><p>CPU指令的执行可以分为5个阶段：取指令、指令译码、执行指令、访存取数、结果写回。</p>
<p><strong>流水线</strong>：一套控制单元可以同时执行多条指令，不需要等到上一条指令执行完就可以执行下一条指令。</p>
<p><strong>超标量</strong>：一个 CPU 核有多套控制单元，因此可以有多条 pipeline 并发执行。CPU 还会维护一个乱序执行的指令窗口，窗口中的无数据依赖的指令就可以被取来并发执行。并发指令越多越好，因为这样指令之间没有依赖，并发流水线的执行会更加的流畅。</p>
<h3 id="分支预测"><a href="#分支预测" class="headerlink" title="分支预测"></a>分支预测</h3><p>遇到 if/switch 这种判断跳转的指令时会产生分支预测，分支预测系统会决定流水线接下来是载入紧挨着判断指令的下一条指令，还是载入跳转到另一个地址的指令。如果 CPU 的预测是正确的，那么判断指令结果出来的那一刻，真正需要执行的指令已经执行到尾声了，这时候只需要继续执行即可；如果CPU的预测是错误的，那么会把执行到尾声的错误指令全部清空，恢复到从未执行过的状态，然后再执行正确的指令。</p>
<p>程序分支越少或者是分支预测成功率越高，对流水线的执行就越有利，因为如果预测失败了，是要丢弃当前 pipeline 的所有指令重新 flush，这个过程往往会消耗掉十几个 CPU 周期。</p>
<h3 id="多级存储与数据预取"><a href="#多级存储与数据预取" class="headerlink" title="多级存储与数据预取"></a>多级存储与数据预取</h3><p>当数据在寄存器，cache 或者内存中，CPU 取数据的速度并不是在一个个数量级上的。CPU 取指令/数据的时候并不是直接从内存中取的，通常 CPU 和内存中会有多级缓存，分别为 L1，L2，L3 cache，其中 L1 cache 又可以分为 L1-data cache，L1-instruction cache。先从 cache 中取数据，若不存在，才访问内存。访问内存的时候会同时把访问数据相邻的一些数据一起加载进 cache 中。</p>
<p>预取指的是若数据存在线性访问的模式，CPU会主动把后续的内存块预先加载进cache中。</p>
<h3 id="SIMD"><a href="#SIMD" class="headerlink" title="SIMD"></a>SIMD</h3><p>单指令多数据流，对于数据密集型的程序来说，可能会需要对大量不同的数据进行相同的运算。SIMD 引入了一组大容量的寄存器，比如 128 位，256 位。可以将这多个数据按次序同时放到一个寄存器。同时，CPU 新增了处理这种大容量寄存器的指令，可以在一个指令周期内完成多个数据的运算。</p>
<h2 id="早期解释执行模型"><a href="#早期解释执行模型" class="headerlink" title="早期解释执行模型"></a>早期解释执行模型</h2><p>大多数的 query 解释器模型都是使用基于迭代器的火山模型，如下图所示。每个算子看成一个 iterator，iterator 会提供一个 next 方法，每个 next 方法只会产生一个 tuple，可以理解为一行数据。查询执行的时候，查询树自顶向下调用 next 接口，数据则自底向上被拉取处理，层层计算返回结果。所以火山模型属于 pull 模型。</p>
<img src="/2021/03/28/Vectorization-vs-Compilation-in-Query-Execution/Volcano.jpg" style="zoom:100%;">

<p>Volcano 模型简单灵活，且这种设计不用占用过多的内存。火山模型将更多的内存资源用于磁盘 IO 的缓存设计而没有优化 CPU 的执行效率，这在当时的硬件基础上是很自然的权衡。但是现在 CPU 的硬件环境与大数据场景下，性能表现却差强人意。主要有如下几点原因：</p>
<ol>
<li><p>时间都花在了query plan上，而不是计算上<br>next 函数实现为虚函数，调用虚函数的时候要去查虚函数表，编译器无法对虚函数进行 inline 优化。同时会带来分支预测的开销，导致一次错误的 CPU 分支预测，需要多花费十几个 CPU 周期的开销。</p>
</li>
<li><p>CPU cache利用率低<br>next 方法一次只返回一个元组，元组通常采用行存储，如果仅需访问其中某个字段但是每次都将整行数据填入 CPU cache，将导致那些不会被访问的字段也放在了 Cache 中，使得 cache 利用率非常低。</p>
</li>
</ol>
<h2 id="编译执行"><a href="#编译执行" class="headerlink" title="编译执行"></a>编译执行</h2><p>编译执行指的是运行时期的代码生成生成技术。在执行过程中生成编译执行代码，避免过多的虚函数调用和解析执行，因为在执行之初我们是知道关系代数的 Schema 信息。在具备 Schema 信息的情况下，事先生成好的代码，可以有效减少很多执行分支预测开销。</p>
<img src="/2021/03/28/Vectorization-vs-Compilation-in-Query-Execution/Compilation.jpg" style="zoom:100%;">

<p>上图右边的代码非常紧凑，有效消除了字段个数，字段大小，字段类型，对于数据量特别多的处理场景，可以大大减少CPU开销，提高性能。</p>
<p>编译执行以数据为中心，消灭了火山模型中的大量虚函数调用开销。甚至使大部分指令执行，可以直接从寄存器取数，极大提高了执行效率。</p>
<p>在 Java 中通过 JIT 来实现，在 C++ 中通过 LLVM 来实现 codegen，对于 OLAP 这种运行时间较长的 query 来说，通常编译的时间是可以忽略的。</p>
<h2 id="向量化执行"><a href="#向量化执行" class="headerlink" title="向量化执行"></a>向量化执行</h2><p>向量可以理解为按列组织的一组数据，连续存储的一列数据，在内存中可以表示为一个向量。</p>
<img src="/2021/03/28/Vectorization-vs-Compilation-in-Query-Execution/Vectorization.png" style="zoom:100%;">

<p>向量模型和火山模型的本质区别就在于，数据处理的基本单元不再是按行组织的 tuple，而是按列组织的多个向量，我们常说的一个 chunk 其实就是多个 vector 的集合，就是多个列的意思。</p>
<p>向量化执行好处是：由于每次 next 都是处理一批数据，那么大大减少了虚函数调用的次数，分支预测的成功概率会提升，减少了分支预测的开销，并且充分发挥 SIMD 指令并行计算的优势；还可以和列式存储有效结合在一起，减少数据额外转换的 overhead。</p>
<h2 id="向量化和编译执行比较"><a href="#向量化和编译执行比较" class="headerlink" title="向量化和编译执行比较"></a>向量化和编译执行比较</h2><p>向量化执行的主要访存开销在于像 join 这种算子的物化开销，物化就是从寄存器把数据读到内存中。而编译执行，tuple 可以一直留在寄存器中，一个 operator 处理完后，给另外一个 operator 继续处理。除非遇到不得不物化的情况。</p>
<p>向量化执行模型的循环较短，并发度高，可以同时有更多的指令等待取数。编译执行循环内部会包含多个 operator 的运算，这些有依赖关系的指令占据了大部分的乱序执行窗口，并发度低。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li>Sompolski, J. ,  M. Zukowski , and  P. A. Boncz . “Vectorization vs. Compilation in Query Execution.” International Workshop on Data Management on New Hardware ACM, 2011.</li>
<li>S. Wanderman-Milne and N. Li, “Runtime Code Generation in Cloudera Impala,” IEEE Data Eng. Bull., vol. 37, no. 1, pp. 31–37, 2014.</li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/63996040">向量化与编译执行浅析</a></li>
</ol>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/page/2/">上一页</a></div><div class="pagination-next"><a href="/page/4/">下一页</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/">1</a></li><li><a class="pagination-link" href="/page/2/">2</a></li><li><a class="pagination-link is-current" href="/page/3/">3</a></li><li><a class="pagination-link" href="/page/4/">4</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/7/">7</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/dog.jpg" alt="Iggie Wang (王亮)"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Iggie Wang (王亮)</p><p class="is-size-6 is-block">WNLO, HUST</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Wuhan, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">20</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">0</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">8</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/hey-kong" target="_blank" rel="noopener">关注我</a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://github.com/hey-kong" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li><li><a class="level is-mobile" href="iggiewang@gmail.com" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Email</span></span><span class="level-right"><span class="level-item tag">iggiewang@gmail.com</span></span></a></li></ul></div></div></div><!--!--><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-10-01T06:46:46.000Z">2021-10-01</time></p><p class="title"><a href="/2021/10/01/ALEX-An-Updatable-Adaptive-Learned-Index/">ALEX: An Updatable Adaptive Learned Index</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-09-30T07:54:13.000Z">2021-09-30</time></p><p class="title"><a href="/2021/09/30/gRPC-%E5%9F%BA%E7%A1%80/">gRPC 基础</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-09-20T06:13:26.000Z">2021-09-20</time></p><p class="title"><a href="/2021/09/20/From-WiscKey-to-Bourbon-A-Learned-Index-for-Log-Structured-Merge-Trees/">From WiscKey to Bourbon: A Learned Index for Log-Structured Merge Trees</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-09T05:19:49.000Z">2021-08-09</time></p><p class="title"><a href="/2021/08/09/Octopus-an-RDMA-enabled-Distributed-Persistent-Memory-File-System/">Octopus: an RDMA-enabled Distributed Persistent Memory File System</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-07-28T15:20:51.000Z">2021-07-28</time></p><p class="title"><a href="/2021/07/28/RDMA-%E5%9F%BA%E7%A1%80/">RDMA 基础</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2021/10/"><span class="level-start"><span class="level-item">十月 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/09/"><span class="level-start"><span class="level-item">九月 2021</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/08/"><span class="level-start"><span class="level-item">八月 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/07/"><span class="level-start"><span class="level-item">七月 2021</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/05/"><span class="level-start"><span class="level-item">五月 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/04/"><span class="level-start"><span class="level-item">四月 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/03/"><span class="level-start"><span class="level-item">三月 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/02/"><span class="level-start"><span class="level-item">二月 2021</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/01/"><span class="level-start"><span class="level-item">一月 2021</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/CSAPP/"><span class="tag">CSAPP</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Cache/"><span class="tag">Cache</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Database/"><span class="tag">Database</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/File-System/"><span class="tag">File System</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Key-Value-Store/"><span class="tag">Key-Value Store</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Learned-Index/"><span class="tag">Learned Index</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RDMA/"><span class="tag">RDMA</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Rocksdb/"><span class="tag">Rocksdb</span><span class="tag">3</span></a></div></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">订阅更新</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="订阅"></div></div></form></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">Iggie Wang&#039;s Cyberspace</a><p class="is-size-7"><span>&copy; 2021 王亮</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdnjs.loli.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/cookieconsent/3.1.1/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/js/lightgallery.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdnjs.loli.net/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>