{"pages":[],"posts":[{"title":"About me","text":"Education 武汉大学，软件工程，本科，2017.09~至今 华中科技大学，计算机体系结构，准研究生 Interest 分布式系统 存储系统 数据库 Skill 会写一点点Go，C/C++，Python，JAVA，C# 懂得一点点数据结构与算法 了解一点点系统知识基础 熟悉一点点Linux操作系统 Contact iggiewang@gmail.com","link":"/2021/01/16/About-me/"},{"title":"RocksDB Get 流程","text":"本文对 RocksDB 6.7.3 版本的 Get 流程进行分析。 概述(1) 获取当前的 SuperVersion。SuperVersion 用于管理 CF 的元数据，如当前版本号、内存中的 MemTable 和 Immutable MemTable、SST 文件信息等: 123456Struct SuperVersion { MemTable* mem; MemTableListVersion* imm; Version* current; ...} (2) 从内存读: 尝试从第一步 SuperVersion 中引用的 MemTable 以及Immutable MemTable 中获取对应的值 (3) 从持久化设备读: 首先通过 Table cache 获取到文件的元数据，如布隆过滤器(Bloom Filters)和数据块索引(Indexes)， 如果 Block cache 中缓存了 SST 的数据块，如果命中那就直接读取成功，否则便需要从 SST 中读取数据块并插入到 Block cache 源码分析DBImpl::Get12345678Status DBImpl::Get(const ReadOptions&amp; read_options, ColumnFamilyHandle* column_family, const Slice&amp; key, PinnableSlice* value) { GetImplOptions get_impl_options; get_impl_options.column_family = column_family; get_impl_options.value = value; return GetImpl(read_options, key, get_impl_options);} Rocksdb 的 Get 接口 DBImpl::Get 其实现主要靠 DBImpl::GetImpl 函数调用。 DBImpl::GetImpl1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950Status DBImpl::GetImpl(const ReadOptions&amp; read_options, const Slice&amp; key, ... SuperVersion* sv = GetAndRefSuperVersion(cfd); ... SequenceNumber snapshot; if (read_options.snapshot != nullptr) { if (get_impl_options.callback) { snapshot = get_impl_options. } else { snapshot = reinterpret_cast&lt;const SnapshotImpl*&gt;(read_options.snapshot)-&gt;number_; } } else { .... snapshot = last_seq_same_as_publish_seq_ ? versions_-&gt;LastSequence() : versions_-&gt;LastPublishedSequence(); ... } } ... if (!skip_memtable) { ... if (sv-&gt;mem-&gt;Get(lkey, get_impl_options.value-&gt;GetSelf(), &amp;s, &amp;merge_context, &amp;max_covering_tombstone_seq, read_options, get_impl_options.callback, get_impl_options.is_blob_index)) { ... } else if ((s.ok() || s.IsMergeInProgress()) &amp;&amp; sv-&gt;imm-&gt;Get(lkey, get_impl_options.value-&gt;GetSelf(), &amp;s, &amp;merge_context, &amp;max_covering_tombstone_seq, read_options, get_impl_options.callback, get_impl_options.is_blob_index)) { ... } ... } if (!done) { sv-&gt;current-&gt;Get( read_options, lkey, get_impl_options.value, &amp;s, &amp;merge_context, &amp;max_covering_tombstone_seq, get_impl_options.get_value ? get_impl_options.value_found : nullptr, nullptr, nullptr, get_impl_options.get_value ? get_impl_options.callback : nullptr, get_impl_options.get_value ? get_impl_options.is_blob_index : nullptr, get_impl_options.get_value); ... } ...} DBImpl::GetImpl 获取 SuperVersion 的信息，如果用户未指定 snapshot，需要获取当前的 snapshot。读取时不对 key 加锁，能读到什么数据完全取决于 Options 传入的 snapshot。 SuperVersion 中按照数据的新旧程度排序 MemTable -&gt; MemTableListVersion -&gt; Version，依次按序查找，如果在新的数据中找到符合 snapshot 规则的结果，就可以立即返回，完成本次查找。 MemTable::Get123456789101112131415161718192021222324252627282930313233bool MemTable::Get(const LookupKey&amp; key, std::string* value, Status* s, MergeContext* merge_context, SequenceNumber* max_covering_tombstone_seq, SequenceNumber* seq, const ReadOptions&amp; read_opts, ReadCallback* callback, bool* is_blob_index, bool do_merge) { ... if (bloom_filter_ &amp;&amp; !may_contain) { // iter is null if prefix bloom says the key does not exist PERF_COUNTER_ADD(bloom_memtable_miss_count, 1); *seq = kMaxSequenceNumber; } else { if (bloom_filter_) { PERF_COUNTER_ADD(bloom_memtable_hit_count, 1); } GetFromTable(key, *max_covering_tombstone_seq, do_merge, callback, is_blob_index, value, s, merge_context, seq, &amp;found_final_value, &amp;merge_in_progress); } ...}void MemTable::GetFromTable(const LookupKey&amp; key, SequenceNumber max_covering_tombstone_seq, bool do_merge, ReadCallback* callback, bool* is_blob_index, std::string* value, Status* s, MergeContext* merge_context, SequenceNumber* seq, bool* found_final_value, bool* merge_in_progress) { ... table_-&gt;Get(key, &amp;saver, SaveValue); *seq = saver.seq;} 利用 MemTableRep 的 Get 函数进行查找（以 SkipListRep 实现为例，在 skiplist 中进行查找，从 seek 到的位置开始向后遍历，遍历 entry 是否符合SaveValue 定义的规则）。SaveValue 函数查看当前 entry 是否还是当前查找的 key，如果不是则返回；查看当前 entry 的 snapshot 是否小于或等于需要查找的 snapshot，不符合则继续循环。如果 entry 的snapshot 符合上述条件，那么则跳出循环，返回查找结果。 MemTableListVersion::Get123456789bool Get(const LookupKey&amp; key, std::string* value, Status* s, MergeContext* merge_context, SequenceNumber* max_covering_tombstone_seq, const ReadOptions&amp; read_opts, ReadCallback* callback = nullptr, bool* is_blob_index = nullptr) { SequenceNumber seq; return Get(key, value, s, merge_context, max_covering_tombstone_seq, &amp;seq, read_opts, callback, is_blob_index);} MemTableListVersion 用链表的形式保存了所有 Immutable memtable 的结构，查找时，按时间序依次查找于每一个 memtable，如果任何一个 memtable 查找到结果则立即返回，即返回最新的返回值。具体 memtable 查找见上述 MemTable::Get 接口。 Version::Get123456789101112131415161718192021222324252627void Version::Get(const ReadOptions&amp; read_options, const LookupKey&amp; k, PinnableSlice* value, Status* status, MergeContext* merge_context, SequenceNumber* max_covering_tombstone_seq, bool* value_found, bool* key_exists, SequenceNumber* seq, ReadCallback* callback, bool* is_blob, bool do_merge) { ... FilePicker fp( storage_info_.files_, user_key, ikey, &amp;storage_info_.level_files_brief_, storage_info_.num_non_empty_levels_, &amp;storage_info_.file_indexer_, user_comparator(), internal_comparator()); FdWithKeyRange* f = fp.GetNextFile(); while (f != nullptr) { ... *status = table_cache_-&gt;Get( read_options, *internal_comparator(), *f-&gt;file_metadata, ikey, &amp;get_context, mutable_cf_options_.prefix_extractor.get(), cfd_-&gt;internal_stats()-&gt;GetFileReadHist(fp.GetHitFileLevel()), IsFilterSkipped(static_cast&lt;int&gt;(fp.GetHitFileLevel()), fp.IsHitFileLastInLevel()), fp.GetCurrentLevel()); ... f = fp.GetNextFile(); } ...} GetNextFile 函数会遍历所有的 level，然后再遍历每个 level 的所有的文件，这里会对 level 0 的文件做一个特殊处理，这是因为只有 level 0 的 SST 的 range 不是有序的，因此我们每次查找需要查找所有的文件，也就是会一个个的遍历；而在非 level 0，我们只需要按照二分查找来得到对应的文件即可，如果二分查找不存在，那么我就需要进入下一个 level 进行查找。 调用 TableCache::Get 遍历单个 SST 文件，如果查找到结果立即返回。 TableCache::Get123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109Status TableCache::Get(const ReadOptions&amp; options, const InternalKeyComparator&amp; internal_comparator, const FileMetaData&amp; file_meta, const Slice&amp; k, GetContext* get_context, const SliceTransform* prefix_extractor, HistogramImpl* file_read_hist, bool skip_filters, int level) { auto&amp; fd = file_meta.fd; std::string* row_cache_entry = nullptr; bool done = false;#ifndef ROCKSDB_LITE IterKey row_cache_key; std::string row_cache_entry_buffer; // Check row cache if enabled. Since row cache does not currently store // sequence numbers, we cannot use it if we need to fetch the sequence. if (ioptions_.row_cache &amp;&amp; !get_context-&gt;NeedToReadSequence()) { auto user_key = ExtractUserKey(k); CreateRowCacheKeyPrefix(options, fd, k, get_context, row_cache_key); done = GetFromRowCache(user_key, row_cache_key, row_cache_key.Size(), get_context); if (!done) { row_cache_entry = &amp;row_cache_entry_buffer; } }#endif // ROCKSDB_LITE Status s; TableReader* t = fd.table_reader; Cache::Handle* handle = nullptr; if (!done &amp;&amp; s.ok()) { if (t == nullptr) { s = FindTable( file_options_, internal_comparator, fd, &amp;handle, prefix_extractor, options.read_tier == kBlockCacheTier /* no_io */, true /* record_read_stats */, file_read_hist, skip_filters, level); if (s.ok()) { t = GetTableReaderFromHandle(handle); } } SequenceNumber* max_covering_tombstone_seq = get_context-&gt;max_covering_tombstone_seq(); if (s.ok() &amp;&amp; max_covering_tombstone_seq != nullptr &amp;&amp; !options.ignore_range_deletions) { std::unique_ptr&lt;FragmentedRangeTombstoneIterator&gt; range_del_iter( t-&gt;NewRangeTombstoneIterator(options)); if (range_del_iter != nullptr) { *max_covering_tombstone_seq = std::max( *max_covering_tombstone_seq, range_del_iter-&gt;MaxCoveringTombstoneSeqnum(ExtractUserKey(k))); } } if (s.ok()) { get_context-&gt;SetReplayLog(row_cache_entry); // nullptr if no cache. s = t-&gt;Get(options, k, get_context, prefix_extractor, skip_filters); get_context-&gt;SetReplayLog(nullptr); } else if (options.read_tier == kBlockCacheTier &amp;&amp; s.IsIncomplete()) { // Couldn't find Table in cache but treat as kFound if no_io set get_context-&gt;MarkKeyMayExist(); s = Status::OK(); done = true; } }#ifndef ROCKSDB_LITE // Put the replay log in row cache only if something was found. if (!done &amp;&amp; s.ok() &amp;&amp; row_cache_entry &amp;&amp; !row_cache_entry-&gt;empty()) { size_t charge = row_cache_key.Size() + row_cache_entry-&gt;size() + sizeof(std::string); void* row_ptr = new std::string(std::move(*row_cache_entry)); ioptions_.row_cache-&gt;Insert(row_cache_key.GetUserKey(), row_ptr, charge, &amp;DeleteEntry&lt;std::string&gt;); }#endif // ROCKSDB_LITE if (handle != nullptr) { ReleaseHandle(handle); } return s;}Status TableCache::FindTable(const FileOptions&amp; file_options, const InternalKeyComparator&amp; internal_comparator, const FileDescriptor&amp; fd, Cache::Handle** handle, const SliceTransform* prefix_extractor, const bool no_io, bool record_read_stats, HistogramImpl* file_read_hist, bool skip_filters, int level, bool prefetch_index_and_filter_in_cache) { ... std::unique_ptr&lt;TableReader&gt; table_reader; s = GetTableReader(file_options, internal_comparator, fd, false /* sequential mode */, record_read_stats, file_read_hist, &amp;table_reader, prefix_extractor, skip_filters, level, prefetch_index_and_filter_in_cache); if (!s.ok()) { assert(table_reader == nullptr); RecordTick(ioptions_.statistics, NO_FILE_ERRORS); // We do not cache error results so that if the error is transient, // or somebody repairs the file, we recover automatically. } else { s = cache_-&gt;Insert(key, table_reader.get(), 1, &amp;DeleteEntry&lt;TableReader&gt;, handle); if (s.ok()) { // Release ownership of table reader. table_reader.release(); } ... return s;} 如果 row_cache 打开，首先它会计算 row cache 的 key，再在row cache 中进行一次查找，如果有对应的值则直接返回结果，否则则将会在对应的 SST 读取传递进来的 key。 调用 FindTable，进行对应 table_reader 的读取以及进行 Table cache。 接下来调用 t-&gt;Get，从 Block cache 或者 SST 中读取数据。 最后，如果 row_cache 打开，把读取的数据插入到 row cache 中。 BlockBasedTable::Get12345678for (iiter-&gt;Seek(key); iiter-&gt;Valid()&amp;&amp;!done; iiter-&gt;Next()) { ... NewDataBlockIterator(&amp;biter); for(; biter.Valid; biter.Next()) { ... get_context-&gt;SaveValue(biter-&gt;Value()); }} 在 Table Cache 中，假设最终缓存的 table reader 是一个 BlockBasedTable 对象，调用 BlockBasedTable::Get。 首先，根据 Table 的元数据信息（布隆过滤器，数据块Index）查找 SST 内部的 Block。 调用 NewDataBlockIterator，若 Block 在 Block Cache 当中，直接返回对象地址，否则，发生磁盘IO，读取 SST 的 Block，构造 Block 对象并缓存其地址在 Block Cache 中。 找到 key 对应的 value，调用 get_context-&gt;SaveValue，直接将 Block 中的数据地址赋给用户传进来的 PinnableSlice* 中，减少了一次数据拷贝，并用引用计数避免 Block 被淘汰值被清除。 回顾 参考 Rocksdb Source Code 6.7.3 Rocksdb Code Analysis Get MySQL · RocksDB · 数据的读取(二) 使用PinnableSlice减少Get时的内存拷贝","link":"/2021/01/17/Rocksdb-Get/"},{"title":"从 Row Cache 的 Get 来看 Rocksdb LRUCache","text":"本文简单介绍 RocksDB 6.7.3 版本的 LRUCache。 Row CacheRow Cache 对查找的 key 在 SST 中对应的 value 进行 cache。如果 row_cache 打开，在 TableCache::Get 函数中，会调用 CreateRowCacheKeyPrefix 和 GetFromRowCache 获取 row cache 的 key（fd_number + seq_no + user_key），在 GetFromRowCache 中，会调用 row_cache-&gt;Lookup，得到 row cache 缓存的 row_handle，构造 found_row_cache_entry 指针指向 value，利用 Cleannable 类的特性，可以通过减少一次对 value 内存拷贝的方式来获取最终的结果。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566Status TableCache::Get(const ReadOptions&amp; options, const InternalKeyComparator&amp; internal_comparator, const FileMetaData&amp; file_meta, const Slice&amp; k, GetContext* get_context, const SliceTransform* prefix_extractor, HistogramImpl* file_read_hist, bool skip_filters, int level) { ... if (ioptions_.row_cache &amp;&amp; !get_context-&gt;NeedToReadSequence()) { auto user_key = ExtractUserKey(k); CreateRowCacheKeyPrefix(options, fd, k, get_context, row_cache_key); done = GetFromRowCache(user_key, row_cache_key, row_cache_key.Size(), get_context); if (!done) { row_cache_entry = &amp;row_cache_entry_buffer; } } ...}void TableCache::CreateRowCacheKeyPrefix(const ReadOptions&amp; options, const FileDescriptor&amp; fd, const Slice&amp; internal_key, GetContext* get_context, IterKey&amp; row_cache_key) { uint64_t fd_number = fd.GetNumber(); uint64_t seq_no = 0; ... AppendVarint64(&amp;row_cache_key, fd_number); AppendVarint64(&amp;row_cache_key, seq_no);}bool TableCache::GetFromRowCache(const Slice&amp; user_key, IterKey&amp; row_cache_key, size_t prefix_size, GetContext* get_context) { bool found = false; row_cache_key.TrimAppend(prefix_size, user_key.data(), user_key.size()); if (auto row_handle = ioptions_.row_cache-&gt;Lookup(row_cache_key.GetUserKey())) { // Cleanable routine to release the cache entry Cleanable value_pinner; auto release_cache_entry_func = [](void* cache_to_clean, void* cache_handle) { ((Cache*)cache_to_clean)-&gt;Release((Cache::Handle*)cache_handle); }; auto found_row_cache_entry = static_cast&lt;const std::string*&gt;(ioptions_.row_cache-&gt;Value(row_handle)); // If it comes here value is located on the cache. // found_row_cache_entry points to the value on cache, // and value_pinner has cleanup procedure for the cached entry. // After replayGetContextLog() returns, get_context.pinnable_slice_ // will point to cache entry buffer (or a copy based on that) and // cleanup routine under value_pinner will be delegated to // get_context.pinnable_slice_. Cache entry is released when // get_context.pinnable_slice_ is reset. value_pinner.RegisterCleanup(release_cache_entry_func, ioptions_.row_cache.get(), row_handle); replayGetContextLog(*found_row_cache_entry, user_key, get_context, &amp;value_pinner); RecordTick(ioptions_.statistics, ROW_CACHE_HIT); found = true; } else { RecordTick(ioptions_.statistics, ROW_CACHE_MISS); } return found;} LRUCache 类 Cache定义了 Cache 的接口，包括 Insert, Lookup, Release 等操作。 ShardedCache支持对 Cache 进行分桶，分桶数量为 2^num_shard_bits，每个桶的容量相等。分桶的依据是取 key 的 hash 值的高 num_shard_bits 位。 LRUCache实现了 ShardedCache，维护了一个 LRUCacheShard 数组，一个 shard 就是一个桶。 CacheShard定义了一个桶的接口，包括 Insert, Lookup, Release 等操作，Cache 的相关调用经过分桶处理后，都会调用指定桶的对应操作。 LRUCacheShard实现了 CacheShard，维护了一个 LRU list 和 hash table，用来实现 LRU 策略，他们的成员类型都是 LRUHandle。 LRUHandle保存 key 和 value 的单元，并且包含前向和后续指针，可以组成双向循环链表作为 LRU list。 LRUHandleTablehash table 的实现，根据 key 再次做了分组处理，并且尽量保证每个桶中只有一个元素，元素类型为 LRUHandle。提供了Lookup, Insert, Remove操作。 Lookup在 GetFromRowCache 中，会调用 row_cache-&gt;Lookup，这里实际调用的是 ShardedCache::Lookup 1234Cache::Handle* ShardedCache::Lookup(const Slice&amp; key, Statistics* /*stats*/) { uint32_t hash = HashSlice(key); return GetShard(Shard(hash))-&gt;Lookup(key, hash);} 获取哈希值，根据 hash 值的高 num_shard_bits 位获取 shard，再调用 LRUCacheShard::Lookup 1234567891011121314Cache::Handle* LRUCacheShard::Lookup(const Slice&amp; key, uint32_t hash) { MutexLock l(&amp;mutex_); LRUHandle* e = table_.Lookup(key, hash); if (e != nullptr) { assert(e-&gt;InCache()); if (!e-&gt;HasRefs()) { // The entry is in LRU since it's in hash and has no external references LRU_Remove(e); } e-&gt;Ref(); e-&gt;SetHit(); } return reinterpret_cast&lt;Cache::Handle*&gt;(e);} LRUCacheShard::Lookup 中又会调用 LRUHandleTable::Lookup，在 FindPointer 中，hash 到特定位置后，如果当前位置的 hash 和当前 hash 不一样，或者 key 不一样，并且指针也不为空，则继续向下找，直到找到 1234567891011LRUHandle* LRUHandleTable::Lookup(const Slice&amp; key, uint32_t hash) { return *FindPointer(key, hash);}LRUHandle** LRUHandleTable::FindPointer(const Slice&amp; key, uint32_t hash) { LRUHandle** ptr = &amp;list_[hash &amp; (length_ - 1)]; while (*ptr != nullptr &amp;&amp; ((*ptr)-&gt;hash != hash || key != (*ptr)-&gt;key())) { ptr = &amp;(*ptr)-&gt;next_hash; } return ptr;} 总结LRUCache 就是把多个 LRUCacheShard 组合起来，每个 LRUCacheShard 维护了一个 LRUHandle list 和 hash table，LRUHandleTable 用拉链法实现哈希表。通过对缓存的 Lookup 调用链分析可以看到具体的实现非常简练。 参考 Rocksdb Source Code 6.7.3 RocksDB. LRUCache源码分析 RocksDB中的LRUCache","link":"/2021/01/18/Rocksdb-Cache/"}],"tags":[{"name":"Rocksdb","slug":"Rocksdb","link":"/tags/Rocksdb/"}],"categories":[]}