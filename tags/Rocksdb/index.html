<!doctype html>
<html lang="de"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta><title>Etiqueta: Rocksdb - Iggie Wang&#039;s Cyberspace</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Iggie Wang&#039;s Cyberspace"><meta name="msapplication-TileImage" content="/img/dog.jpg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Iggie Wang&#039;s Cyberspace"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="Iggie Wang&#039;s Cyberspace"><meta property="og:url" content="https://www.iggiewang.cn/"><meta property="og:site_name" content="Iggie Wang&#039;s Cyberspace"><meta property="og:image" content="https://www.iggiewang.cn/img/og_image.png"><meta property="article:author" content="王亮"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://www.iggiewang.cn"},"headline":"Iggie Wang's Cyberspace","image":["https://www.iggiewang.cn/img/og_image.png"],"author":{"@type":"Person","name":"王亮"},"publisher":{"@type":"Organization","name":"Iggie Wang's Cyberspace","logo":{"@type":"ImageObject","url":null}},"description":""}</script><link rel="icon" href="/img/dog.jpg"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.15.2/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/cookieconsent/3.1.1/cookieconsent.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/pace/1.0.2/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.3.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">Iggie Wang&#039;s Cyberspace</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item search" title="Buscar" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">Etiquetas</a></li><li class="is-active"><a href="#" aria-current="page">Rocksdb</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Publicado hace&nbsp;<time dateTime="2021-04-05T08:33:37.000Z" title="2021/4/5 下午4:33:37">2021-04-05</time></span><span class="level-item">16 minutes de lectura (Aproximadamente 2329 palabras)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/04/05/RocksDB-WriteImpl-%E6%B5%81%E7%A8%8B/">RocksDB WriteImpl 流程</a></h1><div class="content"><p><code>本文对 RocksDB 6.7.3 版本的 WriteImpl 流程进行分析。</code></p>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>RocksDB 写入实现主要在 DBImpl::WriteImpl 中，过程主要分为以下三步：</p>
<ul>
<li>把 WriteBatch 加入队列，多个 WriteBatch 成为一个 WriteGroup</li>
<li>将该 WriteGroup 所有的记录对应的日志写到 WAL 文件中</li>
<li>将该 WriteGroup 所有的 WriteBatch 中的一条或者多条记录写到内存中的 Memtable 中</li>
</ul>
<p>其中，每个 WriteBatch 代表一个事务的提交，可以包含多条操作，可以通过调用 WriteBatch::Put/Delete 等操作将对应多条的 key/value 记录加入 WriteBatch 中。</p>
<h2 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h2><h3 id="WriteThread-JoinBatchGroup"><a href="#WriteThread-JoinBatchGroup" class="headerlink" title="WriteThread::JoinBatchGroup"></a>WriteThread::JoinBatchGroup</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">static WriteThread::AdaptationContext jbg_ctx(<span class="string">&quot;JoinBatchGroup&quot;</span>);</span><br><span class="line">void WriteThread::JoinBatchGroup(Writer* w) &#123;</span><br><span class="line">  TEST_SYNC_POINT_CALLBACK(<span class="string">&quot;WriteThread::JoinBatchGroup:Start&quot;</span>, w);</span><br><span class="line">  assert(w-&gt;batch != nullptr);</span><br><span class="line"></span><br><span class="line">  bool linked_as_leader = LinkOne(w, &amp;newest_writer_);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (linked_as_leader) &#123;</span><br><span class="line">    SetState(w, STATE_GROUP_LEADER);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  TEST_SYNC_POINT_CALLBACK(<span class="string">&quot;WriteThread::JoinBatchGroup:Wait&quot;</span>, w);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (!linked_as_leader) &#123;</span><br><span class="line">    /**</span><br><span class="line">     * Wait util:</span><br><span class="line">     * 1) An existing leader pick us as the new leader when it finishes</span><br><span class="line">     * 2) An existing leader pick us as its follewer and</span><br><span class="line">     * 2.1) finishes the memtable writes on our behalf</span><br><span class="line">     * 2.2) Or tell us to finish the memtable writes <span class="keyword">in</span> pralallel</span><br><span class="line">     * 3) (pipelined write) An existing leader pick us as its follower and</span><br><span class="line">     *    finish book-keeping and WAL write <span class="keyword">for</span> us, enqueue us as pending</span><br><span class="line">     *    memtable writer, and</span><br><span class="line">     * 3.1) we become memtable writer group leader, or</span><br><span class="line">     * 3.2) an existing memtable writer group leader tell us to finish memtable</span><br><span class="line">     *      writes <span class="keyword">in</span> parallel.</span><br><span class="line">     */</span><br><span class="line">    TEST_SYNC_POINT_CALLBACK(<span class="string">&quot;WriteThread::JoinBatchGroup:BeganWaiting&quot;</span>, w);</span><br><span class="line">    AwaitState(w, STATE_GROUP_LEADER | STATE_MEMTABLE_WRITER_LEADER |</span><br><span class="line">                      STATE_PARALLEL_MEMTABLE_WRITER | STATE_COMPLETED,</span><br><span class="line">               &amp;jbg_ctx);</span><br><span class="line">    TEST_SYNC_POINT_CALLBACK(<span class="string">&quot;WriteThread::JoinBatchGroup:DoneWaiting&quot;</span>, w);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>每个事务提交请求都会生成一个 WriteBatch 对象，进入 WriteImpl 函数后各自的线程首先调用 JoinBatchGroup 来加入到队列。该队列主要核心的实现在于 LinkOne 函数，通过 CAS 无锁将多个线程的请求组成请求链表：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">bool WriteThread::LinkOne(Writer* w, std::atomic&lt;Writer*&gt;* newest_writer) &#123;</span><br><span class="line">  assert(newest_writer != nullptr);</span><br><span class="line">  assert(w-&gt;state == STATE_INIT);</span><br><span class="line">  Writer* writers = newest_writer-&gt;load(std::memory_order_relaxed);</span><br><span class="line">  <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">    // If write stall <span class="keyword">in</span> effect, and w-&gt;no_slowdown is not <span class="literal">true</span>,</span><br><span class="line">    // block here until stall is cleared. If its <span class="literal">true</span>, <span class="keyword">then</span> <span class="built_in">return</span></span><br><span class="line">    // immediately</span><br><span class="line">    <span class="keyword">if</span> (writers == &amp;write_stall_dummy_) &#123;</span><br><span class="line">      <span class="keyword">if</span> (w-&gt;no_slowdown) &#123;</span><br><span class="line">        w-&gt;status = Status::Incomplete(<span class="string">&quot;Write stall&quot;</span>);</span><br><span class="line">        SetState(w, STATE_COMPLETED);</span><br><span class="line">        <span class="built_in">return</span> <span class="literal">false</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      // Since no_slowdown is <span class="literal">false</span>, <span class="built_in">wait</span> here to be notified of the write</span><br><span class="line">      // stall clearing</span><br><span class="line">      &#123;</span><br><span class="line">        MutexLock lock(&amp;stall_mu_);</span><br><span class="line">        writers = newest_writer-&gt;load(std::memory_order_relaxed);</span><br><span class="line">        <span class="keyword">if</span> (writers == &amp;write_stall_dummy_) &#123;</span><br><span class="line">          stall_cv_.Wait();</span><br><span class="line">          // Load newest_writers_ again since it may have changed</span><br><span class="line">          writers = newest_writer-&gt;load(std::memory_order_relaxed);</span><br><span class="line">          <span class="built_in">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    w-&gt;link_older = writers;</span><br><span class="line">    <span class="keyword">if</span> (newest_writer-&gt;compare_exchange_weak(writers, w)) &#123;</span><br><span class="line">      <span class="built_in">return</span> (writers == nullptr);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>write_group 链表结构如下：</p>
<img src="/2021/04/05/RocksDB-WriteImpl-%E6%B5%81%E7%A8%8B/write_group.png" style="zoom:100%;">

<p>每个 writer 在头部插入，插入时如果发现 link_older 为空，则此 writer 成为 write_group 的 Leader（即链表尾为 Leader）。</p>
<p>在 JoinBatchGroup 中，如果 writer 不是 Leader（在后文把不是 Leader 的 writer 称为 Follower），则会调用 AwaitState 等待被唤醒。</p>
<blockquote>
<p>PS：由于条件锁 Context Switches 代价高，Rocksdb 在 AwaitState 也做了优化，将 pthread_cond_wait 拆成 3 步来做，本文不对该优化进行详细描述。</p>
</blockquote>
<h3 id="WriteImpl-写日志"><a href="#WriteImpl-写日志" class="headerlink" title="WriteImpl 写日志"></a>WriteImpl 写日志</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (w.state == WriteThread::STATE_GROUP_LEADER) &#123;</span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">  last_batch_group_size_ =</span><br><span class="line">      write_thread_.EnterAsBatchGroupLeader(&amp;w, &amp;wal_write_group);</span><br><span class="line">  const SequenceNumber current_sequence =</span><br><span class="line">      write_thread_.UpdateLastSequence(versions_-&gt;LastSequence()) + 1;</span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (w.status.ok() &amp;&amp; !write_options.disableWAL) &#123;</span><br><span class="line">    PERF_TIMER_GUARD(write_wal_time);</span><br><span class="line">    stats-&gt;AddDBStats(InternalStats::kIntStatsWriteDoneBySelf, 1);</span><br><span class="line">    RecordTick(stats_, WRITE_DONE_BY_SELF, 1);</span><br><span class="line">    <span class="keyword">if</span> (wal_write_group.size &gt; 1) &#123;</span><br><span class="line">      stats-&gt;AddDBStats(InternalStats::kIntStatsWriteDoneByOther,</span><br><span class="line">                        wal_write_group.size - 1);</span><br><span class="line">      RecordTick(stats_, WRITE_DONE_BY_OTHER, wal_write_group.size - 1);</span><br><span class="line">    &#125;</span><br><span class="line">    w.status = WriteToWAL(wal_write_group, log_writer, log_used,</span><br><span class="line">                          need_log_sync, need_log_dir_sync, current_sequence);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">  write_thread_.ExitAsBatchGroupLeader(wal_write_group, w.status);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>成为 Leader 的 writer，负责批量写入 WAL。在写 WAL 前，首先调用 EnterAsBatchGroupLeader 函数：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line">size_t WriteThread::EnterAsBatchGroupLeader(Writer* leader,</span><br><span class="line">                                            WriteGroup* write_group) &#123;</span><br><span class="line">  assert(leader-&gt;link_older == nullptr);</span><br><span class="line">  assert(leader-&gt;batch != nullptr);</span><br><span class="line">  assert(write_group != nullptr);</span><br><span class="line"></span><br><span class="line">  size_t size = WriteBatchInternal::ByteSize(leader-&gt;batch);</span><br><span class="line"></span><br><span class="line">  // Allow the group to grow up to a maximum size, but <span class="keyword">if</span> the</span><br><span class="line">  // original write is small, <span class="built_in">limit</span> the growth so we <span class="keyword">do</span> not slow</span><br><span class="line">  // down the small write too much.</span><br><span class="line">  size_t max_size = max_write_batch_group_size_bytes;</span><br><span class="line">  const uint64_t min_batch_size_bytes = max_write_batch_group_size_bytes / 8;</span><br><span class="line">  <span class="keyword">if</span> (size &lt;= min_batch_size_bytes) &#123;</span><br><span class="line">    max_size = size + min_batch_size_bytes;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  leader-&gt;write_group = write_group;</span><br><span class="line">  write_group-&gt;leader = leader;</span><br><span class="line">  write_group-&gt;last_writer = leader;</span><br><span class="line">  write_group-&gt;size = 1;</span><br><span class="line">  Writer* newest_writer = newest_writer_.load(std::memory_order_acquire);</span><br><span class="line"></span><br><span class="line">  // This is safe regardless of any db mutex status of the <span class="built_in">caller</span>. Previous</span><br><span class="line">  // calls to ExitAsGroupLeader either didn<span class="string">&#x27;t call CreateMissingNewerLinks</span></span><br><span class="line"><span class="string">  // (they emptied the list and then we added ourself as leader) or had to</span></span><br><span class="line"><span class="string">  // explicitly wake us up (the list was non-empty when we added ourself,</span></span><br><span class="line"><span class="string">  // so we have already received our MarkJoined).</span></span><br><span class="line"><span class="string">  CreateMissingNewerLinks(newest_writer);</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  // Tricky. Iteration start (leader) is exclusive and finish</span></span><br><span class="line"><span class="string">  // (newest_writer) is inclusive. Iteration goes from old to new.</span></span><br><span class="line"><span class="string">  Writer* w = leader;</span></span><br><span class="line"><span class="string">  while (w != newest_writer) &#123;</span></span><br><span class="line"><span class="string">    w = w-&gt;link_newer;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    if (w-&gt;sync &amp;&amp; !leader-&gt;sync) &#123;</span></span><br><span class="line"><span class="string">      // Do not include a sync write into a batch handled by a non-sync write.</span></span><br><span class="line"><span class="string">      break;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    if (w-&gt;no_slowdown != leader-&gt;no_slowdown) &#123;</span></span><br><span class="line"><span class="string">      // Do not mix writes that are ok with delays with the ones that</span></span><br><span class="line"><span class="string">      // request fail on delays.</span></span><br><span class="line"><span class="string">      break;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    if (w-&gt;disable_wal != leader-&gt;disable_wal) &#123;</span></span><br><span class="line"><span class="string">      // Do not mix writes that enable WAL with the ones whose</span></span><br><span class="line"><span class="string">      // WAL disabled.</span></span><br><span class="line"><span class="string">      break;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    if (w-&gt;batch == nullptr) &#123;</span></span><br><span class="line"><span class="string">      // Do not include those writes with nullptr batch. Those are not writes,</span></span><br><span class="line"><span class="string">      // those are something else. They want to be alone</span></span><br><span class="line"><span class="string">      break;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    if (w-&gt;callback != nullptr &amp;&amp; !w-&gt;callback-&gt;AllowWriteBatching()) &#123;</span></span><br><span class="line"><span class="string">      // dont batch writes that don&#x27;</span>t want to be batched</span><br><span class="line">      <span class="built_in">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    auto batch_size = WriteBatchInternal::ByteSize(w-&gt;batch);</span><br><span class="line">    <span class="keyword">if</span> (size + batch_size &gt; max_size) &#123;</span><br><span class="line">      // Do not make batch too big</span><br><span class="line">      <span class="built_in">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    w-&gt;write_group = write_group;</span><br><span class="line">    size += batch_size;</span><br><span class="line">    write_group-&gt;last_writer = w;</span><br><span class="line">    write_group-&gt;size++;</span><br><span class="line">  &#125;</span><br><span class="line">  TEST_SYNC_POINT_CALLBACK(<span class="string">&quot;WriteThread::EnterAsBatchGroupLeader:End&quot;</span>, w);</span><br><span class="line">  <span class="built_in">return</span> size;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在这里，通过 CreateMissingNewerLinks 函数来生成一个双向链表，使得可以从 Leader 开始顺序写。创建完成反向写请求链表之后，则开始计算有多少个写请求可以批量的进行，同时更新 write_group 中的批量写尺寸以及个数等信息，EnterAsBatchGroupLeader 取队列时会把此刻所有的 writer 一次性全取完。</p>
<p>该操作完成之后，则进入写 WAL 的流程了。调用 WriteToWAL，在 MergeBatch 函数中，将根据 write_group 生成一个 merged_batch，该 merged_batch 中记录着应当被写入 WAL 的内容。接着就通过 WriteToWAL 将 merged_batch 写入 WAL 中，这里会根据是否设置了 sync 来决定是否对 WAL 进行落盘操作。</p>
<blockquote>
<p>PS：这里有一个优化点，在生成 merged_batch 的时候，假设该写请求的尺寸为一并且该请求需要写 WAL，则 merged_batch 直接复用了该写请求；反之则会复用一个 tmp_batch_ 对象避免频繁的生成 WriteBatch 对象。在写完 WAL 之后，假设复用了 tmp_batch_，则会清空该对象。</p>
</blockquote>
<p>最后，调用 ExitAsBatchGroupLeader，该函数会决定该 Leader 是否为 STATE_MEMTABLE_WRITER_LEADER（MEMTABLE_WRITER_LEADER数量 &lt;= GROUP_LEADER数量），从而进行写 Memtable 流程。</p>
<h3 id="WriteImpl-写-Memtable"><a href="#WriteImpl-写-Memtable" class="headerlink" title="WriteImpl 写 Memtable"></a>WriteImpl 写 Memtable</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">WriteThread::WriteGroup memtable_write_group;</span><br><span class="line">  <span class="keyword">if</span> (w.state == WriteThread::STATE_MEMTABLE_WRITER_LEADER) &#123;</span><br><span class="line">    PERF_TIMER_GUARD(write_memtable_time);</span><br><span class="line">    assert(w.ShouldWriteToMemtable());</span><br><span class="line">    write_thread_.EnterAsMemTableWriter(&amp;w, &amp;memtable_write_group);</span><br><span class="line">    <span class="keyword">if</span> (memtable_write_group.size &gt; 1 &amp;&amp;</span><br><span class="line">        immutable_db_options_.allow_concurrent_memtable_write) &#123;</span><br><span class="line">      write_thread_.LaunchParallelMemTableWriters(&amp;memtable_write_group);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      memtable_write_group.status = WriteBatchInternal::InsertInto(</span><br><span class="line">          memtable_write_group, w.sequence, column_family_memtables_.get(),</span><br><span class="line">          &amp;flush_scheduler_, &amp;trim_history_scheduler_,</span><br><span class="line">          write_options.ignore_missing_column_families, 0 /*log_number*/, this,</span><br><span class="line">          <span class="literal">false</span> /*concurrent_memtable_writes*/, seq_per_batch_, batch_per_txn_);</span><br><span class="line">      versions_-&gt;SetLastSequence(memtable_write_group.last_sequence);</span><br><span class="line">      write_thread_.ExitAsMemTableWriter(&amp;w, memtable_write_group);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (w.state == WriteThread::STATE_PARALLEL_MEMTABLE_WRITER) &#123;</span><br><span class="line">    assert(w.ShouldWriteToMemtable());</span><br><span class="line">    ColumnFamilyMemTablesImpl column_family_memtables(</span><br><span class="line">        versions_-&gt;GetColumnFamilySet());</span><br><span class="line">    w.status = WriteBatchInternal::InsertInto(</span><br><span class="line">        &amp;w, w.sequence, &amp;column_family_memtables, &amp;flush_scheduler_,</span><br><span class="line">        &amp;trim_history_scheduler_, write_options.ignore_missing_column_families,</span><br><span class="line">        0 /*log_number*/, this, <span class="literal">true</span> /*concurrent_memtable_writes*/,</span><br><span class="line">        <span class="literal">false</span> /*seq_per_batch*/, 0 /*batch_cnt*/, <span class="literal">true</span> /*batch_per_txn*/,</span><br><span class="line">        write_options.memtable_insert_hint_per_batch);</span><br><span class="line">    <span class="keyword">if</span> (write_thread_.CompleteParallelMemTableWriter(&amp;w)) &#123;</span><br><span class="line">      MemTableInsertStatusCheck(w.status);</span><br><span class="line">      versions_-&gt;SetLastSequence(w.write_group-&gt;last_sequence);</span><br><span class="line">      write_thread_.ExitAsMemTableWriter(&amp;w, *w.write_group);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>RocksDB 有一个 allow_concurrent_memtable_write 的配置项，开启后可以并发写 memtable（memtable 能设置并发写，但是 WAL 文件不能，因为 WAL 是一个追加写的文件，多个 writer 必须要串行化），所以接下来分为串行写和并行写来进行分析。</p>
<h4 id="串行写-Memtable"><a href="#串行写-Memtable" class="headerlink" title="串行写 Memtable"></a>串行写 Memtable</h4><p>Leader 调用 InsertInto，对 write_group 进行遍历，将 Leader 和 Follower 的 WriteBatch 写入。之后调用 ExitAsMemTableWriter，把所有 Follower 的状态设置为 STATE_COMPLETED，将它们唤醒，最后再把 Leader 的状态设置为 STATE_COMPLETED。</p>
<h4 id="并行写-Memtable"><a href="#并行写-Memtable" class="headerlink" title="并行写 Memtable"></a>并行写 Memtable</h4><p>调用 LaunchParallelMemTableWriters，遍历 write_group 把 Leader 和 Follower 的状态都设置为 STATE_PARALLEL_MEMTABLE_WRITER，将等待的线程唤醒。最后所有 writer 通过调用 InsertInto 来将 WriteBatch 写入 MemTable 中。writer 完成了 MemTable 的写操作之后，都会调用 CompleteParallelMemTableWriter 函数。该函数会将该 write_group 中运行的任务数减一，当运行中的任务数为零的时候就代表了所有的线程都完成了操作，调用 ExitAsMemTableWriter 把 Leader 的状态设置为 STATE_COMPLETED，反之则会进入等待状态，等待当前其他的写任务完成。</p>
<p>无论是串行写还是并行写，写入 MemTable 完成之后，还有一项工作，就是在取队列时获取 newest_writer_ 和当前时间点处，可能又有很多的写请求产生了，所以批量任务中最后一个完成的线程必须负责重新指定 Leader 给堆积写请求链表的尾部，让其接过 Leader 角色继续进行批量提交。可以看到，串行写和并行写最后都会调用 ExitAsMemTableWriter，正是在该函数中完成了该项工作。</p>
<blockquote>
<p>PS：在高并发场景下，Follow 调用 AwaitState 的平均等待时延差不多是写 WAL 时延的两倍。因为获取 newest_writer_ 后，可能又来了许多写请求，这些写请求先要等待此时的 Leader 完成写流程，还要等待下个 Leader，也就是和这些写请求是同一个 write_group 的 Leader 完成写 WAL 才能被唤醒。</p>
</blockquote>
<h2 id="回顾"><a href="#回顾" class="headerlink" title="回顾"></a>回顾</h2><img src="/2021/04/05/RocksDB-WriteImpl-%E6%B5%81%E7%A8%8B/rocksdb_write.jpg" style="zoom:100%;">

<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><a target="_blank" rel="noopener" href="https://github.com/facebook/rocksdb/tree/v6.7.3">Rocksdb Source Code 6.7.3</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_43479736/article/details/109056437">rocksdb写流程DBImpl::WriteImpl()源代码分析</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/161797527">RocksDB写入流程</a></li>
<li><a target="_blank" rel="noopener" href="https://gocode.cc/project/13/article/183">RocksDB 写流程分析</a></li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Publicado hace&nbsp;<time dateTime="2021-01-18T07:21:39.000Z" title="2021/1/18 下午3:21:39">2021-01-18</time></span><span class="level-item">7 minutes de lectura (Aproximadamente 1065 palabras)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/01/18/Rocksdb-Cache/">从 Row Cache 的 Get 来看 Rocksdb LRUCache</a></h1><div class="content"><p><code>本文简单介绍 RocksDB 6.7.3 版本的 LRUCache。</code></p>
<h2 id="Row-Cache"><a href="#Row-Cache" class="headerlink" title="Row Cache"></a>Row Cache</h2><p>Row Cache 对查找的 key 在 SST 中对应的 value 进行 cache。如果 row_cache 打开，在 TableCache::Get 函数中，会调用 CreateRowCacheKeyPrefix 和 GetFromRowCache 获取 row cache 的 key（fd_number + seq_no + user_key），在 GetFromRowCache 中，会调用 row_cache-&gt;Lookup，得到 row cache 缓存的 row_handle，构造 found_row_cache_entry 指针指向 value，利用 Cleannable 类的特性，可以通过减少一次对 value 内存拷贝的方式来获取最终的结果。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line">Status TableCache::Get(const ReadOptions&amp; options,</span><br><span class="line">                       const InternalKeyComparator&amp; internal_comparator,</span><br><span class="line">                       const FileMetaData&amp; file_meta, const Slice&amp; k,</span><br><span class="line">                       GetContext* get_context,</span><br><span class="line">                       const SliceTransform* prefix_extractor,</span><br><span class="line">                       HistogramImpl* file_read_hist, bool skip_filters,</span><br><span class="line">                       int level) &#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">if</span> (ioptions_.row_cache &amp;&amp; !get_context-&gt;NeedToReadSequence()) &#123;</span><br><span class="line">    auto user_key = ExtractUserKey(k);</span><br><span class="line">    CreateRowCacheKeyPrefix(options, fd, k, get_context, row_cache_key);</span><br><span class="line">    <span class="keyword">done</span> = GetFromRowCache(user_key, row_cache_key, row_cache_key.Size(),</span><br><span class="line">                           get_context);</span><br><span class="line">    <span class="keyword">if</span> (!<span class="keyword">done</span>) &#123;</span><br><span class="line">      row_cache_entry = &amp;row_cache_entry_buffer;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void TableCache::CreateRowCacheKeyPrefix(const ReadOptions&amp; options,</span><br><span class="line">                                         const FileDescriptor&amp; fd,</span><br><span class="line">                                         const Slice&amp; internal_key,</span><br><span class="line">                                         GetContext* get_context,</span><br><span class="line">                                         IterKey&amp; row_cache_key) &#123;</span><br><span class="line">  uint64_t fd_number = fd.GetNumber();</span><br><span class="line">  uint64_t seq_no = 0;</span><br><span class="line">  ...</span><br><span class="line">  AppendVarint64(&amp;row_cache_key, fd_number);</span><br><span class="line">  AppendVarint64(&amp;row_cache_key, seq_no);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">bool TableCache::GetFromRowCache(const Slice&amp; user_key, IterKey&amp; row_cache_key,</span><br><span class="line">                                 size_t prefix_size, GetContext* get_context) &#123;</span><br><span class="line">  bool found = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">  row_cache_key.TrimAppend(prefix_size, user_key.data(), user_key.size());</span><br><span class="line">  <span class="keyword">if</span> (auto row_handle =</span><br><span class="line">          ioptions_.row_cache-&gt;Lookup(row_cache_key.GetUserKey())) &#123;</span><br><span class="line">    // Cleanable routine to release the cache entry</span><br><span class="line">    Cleanable value_pinner;</span><br><span class="line">    auto release_cache_entry_func = [](void* cache_to_clean,</span><br><span class="line">                                       void* cache_handle) &#123;</span><br><span class="line">      ((Cache*)cache_to_clean)-&gt;Release((Cache::Handle*)cache_handle);</span><br><span class="line">    &#125;;</span><br><span class="line">    auto found_row_cache_entry =</span><br><span class="line">        static_cast&lt;const std::string*&gt;(ioptions_.row_cache-&gt;Value(row_handle));</span><br><span class="line">    // If it comes here value is located on the cache.</span><br><span class="line">    // found_row_cache_entry points to the value on cache,</span><br><span class="line">    // and value_pinner has cleanup procedure <span class="keyword">for</span> the cached entry.</span><br><span class="line">    // After replayGetContextLog() returns, get_context.pinnable_slice_</span><br><span class="line">    // will point to cache entry buffer (or a copy based on that) and</span><br><span class="line">    // cleanup routine under value_pinner will be delegated to</span><br><span class="line">    // get_context.pinnable_slice_. Cache entry is released when</span><br><span class="line">    // get_context.pinnable_slice_ is reset.</span><br><span class="line">    value_pinner.RegisterCleanup(release_cache_entry_func,</span><br><span class="line">                                 ioptions_.row_cache.get(), row_handle);</span><br><span class="line">    replayGetContextLog(*found_row_cache_entry, user_key, get_context,</span><br><span class="line">                        &amp;value_pinner);</span><br><span class="line">    RecordTick(ioptions_.statistics, ROW_CACHE_HIT);</span><br><span class="line">    found = <span class="literal">true</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    RecordTick(ioptions_.statistics, ROW_CACHE_MISS);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">return</span> found;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="LRUCache-类"><a href="#LRUCache-类" class="headerlink" title="LRUCache 类"></a>LRUCache 类</h2><img src="/2021/01/18/Rocksdb-Cache/rocksdb_cache.png" style="zoom:100%;">

<ul>
<li><p>Cache<br>定义了 Cache 的接口，包括 Insert, Lookup, Release 等操作。</p>
</li>
<li><p>ShardedCache<br>支持对 Cache 进行分桶，分桶数量为 2^num_shard_bits，每个桶的容量相等。分桶的依据是取 key 的 hash 值的高 num_shard_bits 位。</p>
</li>
<li><p>LRUCache<br>实现了 ShardedCache，维护了一个 LRUCacheShard 数组，一个 shard 就是一个桶。</p>
</li>
<li><p>CacheShard<br>定义了一个桶的接口，包括 Insert, Lookup, Release 等操作，Cache 的相关调用经过分桶处理后，都会调用指定桶的对应操作。</p>
</li>
<li><p>LRUCacheShard<br>实现了 CacheShard，维护了一个 LRU list 和 hash table，用来实现 LRU 策略，他们的成员类型都是 LRUHandle。</p>
</li>
<li><p>LRUHandle<br>保存 key 和 value 的单元，并且包含前向和后续指针，可以组成双向循环链表作为 LRU list。</p>
</li>
<li><p>LRUHandleTable<br>hash table 的实现，根据 key 再次做了分组处理，并且尽量保证每个桶中只有一个元素，元素类型为 LRUHandle。提供了Lookup, Insert, Remove操作。</p>
</li>
</ul>
<h2 id="Lookup"><a href="#Lookup" class="headerlink" title="Lookup"></a>Lookup</h2><p>在 GetFromRowCache 中，会调用 row_cache-&gt;Lookup，这里实际调用的是 ShardedCache::Lookup</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Cache::Handle* ShardedCache::Lookup(const Slice&amp; key, Statistics* /*stats*/) &#123;</span><br><span class="line">  uint32_t <span class="built_in">hash</span> = HashSlice(key);</span><br><span class="line">  <span class="built_in">return</span> GetShard(Shard(<span class="built_in">hash</span>))-&gt;Lookup(key, <span class="built_in">hash</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>获取哈希值，根据 hash 值的高 num_shard_bits 位获取 shard，再调用 LRUCacheShard::Lookup</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Cache::Handle* LRUCacheShard::Lookup(const Slice&amp; key, uint32_t <span class="built_in">hash</span>) &#123;</span><br><span class="line">  MutexLock l(&amp;mutex_);</span><br><span class="line">  LRUHandle* e = table_.Lookup(key, <span class="built_in">hash</span>);</span><br><span class="line">  <span class="keyword">if</span> (e != nullptr) &#123;</span><br><span class="line">    assert(e-&gt;InCache());</span><br><span class="line">    <span class="keyword">if</span> (!e-&gt;HasRefs()) &#123;</span><br><span class="line">      // The entry is <span class="keyword">in</span> LRU since it<span class="string">&#x27;s in hash and has no external references</span></span><br><span class="line"><span class="string">      LRU_Remove(e);</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">    e-&gt;Ref();</span></span><br><span class="line"><span class="string">    e-&gt;SetHit();</span></span><br><span class="line"><span class="string">  &#125;</span></span><br><span class="line"><span class="string">  return reinterpret_cast&lt;Cache::Handle*&gt;(e);</span></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure>
<p>LRUCacheShard::Lookup 中又会调用 LRUHandleTable::Lookup，在 FindPointer 中，hash 到特定位置后，如果当前位置的 hash 和当前 hash 不一样，或者 key 不一样，并且指针也不为空，则继续向下找，直到找到</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">LRUHandle* LRUHandleTable::Lookup(const Slice&amp; key, uint32_t <span class="built_in">hash</span>) &#123;</span><br><span class="line">  <span class="built_in">return</span> *FindPointer(key, <span class="built_in">hash</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">LRUHandle** LRUHandleTable::FindPointer(const Slice&amp; key, uint32_t <span class="built_in">hash</span>) &#123;</span><br><span class="line">  LRUHandle** ptr = &amp;list_[<span class="built_in">hash</span> &amp; (length_ - 1)];</span><br><span class="line">  <span class="keyword">while</span> (*ptr != nullptr &amp;&amp; ((*ptr)-&gt;<span class="built_in">hash</span> != <span class="built_in">hash</span> || key != (*ptr)-&gt;key())) &#123;</span><br><span class="line">    ptr = &amp;(*ptr)-&gt;next_hash;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">return</span> ptr;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>LRUCache 就是把多个 LRUCacheShard 组合起来，每个 LRUCacheShard 维护了一个 LRUHandle list 和 hash table，LRUHandleTable 用拉链法实现哈希表。通过对缓存的 Lookup 调用链分析可以看到具体的实现非常简练。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><a target="_blank" rel="noopener" href="https://github.com/facebook/rocksdb/tree/v6.7.3">Rocksdb Source Code 6.7.3</a></li>
<li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/75b93a664ebe?utm_campaign=maleskine&utm_content=note&utm_medium=seo_notes&utm_source=recommendation">RocksDB. LRUCache源码分析</a></li>
<li><a target="_blank" rel="noopener" href="https://www.yuanguohuo.com/2018/12/23/rocksdb-cache/">RocksDB中的LRUCache</a></li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Publicado hace&nbsp;<time dateTime="2021-01-17T09:22:13.000Z" title="2021/1/17 下午5:22:13">2021-01-17</time></span><span class="level-item">14 minutes de lectura (Aproximadamente 2102 palabras)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/01/17/Rocksdb-Get/">RocksDB Get 流程</a></h1><div class="content"><p><code>本文对 RocksDB 6.7.3 版本的 Get 流程进行分析。</code></p>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>(1) 获取当前的 SuperVersion。SuperVersion 用于管理 CF 的元数据，如当前版本号、内存中的 MemTable 和 Immutable MemTable、SST 文件信息等: </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Struct SuperVersion &#123;</span><br><span class="line">    MemTable*            mem;</span><br><span class="line">    MemTableListVersion* imm;</span><br><span class="line">    Version*             current;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>(2) 从内存读: 尝试从第一步 SuperVersion 中引用的 MemTable 以及Immutable MemTable 中获取对应的值</p>
<p>(3) 从持久化设备读: 首先通过 Table cache 获取到文件的元数据，如布隆过滤器(Bloom Filters)和数据块索引(Indexes)， 如果 Block cache 中缓存了 SST 的数据块，如果命中那就直接读取成功，否则便需要从 SST 中读取数据块并插入到 Block cache</p>
<h2 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h2><h3 id="DBImpl-Get"><a href="#DBImpl-Get" class="headerlink" title="DBImpl::Get"></a>DBImpl::Get</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Status DBImpl::Get(const ReadOptions&amp; read_options,</span><br><span class="line">                   ColumnFamilyHandle* column_family, const Slice&amp; key,</span><br><span class="line">                   PinnableSlice* value) &#123;</span><br><span class="line">  GetImplOptions get_impl_options;</span><br><span class="line">  get_impl_options.column_family = column_family;</span><br><span class="line">  get_impl_options.value = value;</span><br><span class="line">  <span class="built_in">return</span> GetImpl(read_options, key, get_impl_options);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Rocksdb 的 Get 接口 DBImpl::Get 其实现主要靠 DBImpl::GetImpl 函数调用。</p>
<h3 id="DBImpl-GetImpl"><a href="#DBImpl-GetImpl" class="headerlink" title="DBImpl::GetImpl"></a>DBImpl::GetImpl</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">Status DBImpl::GetImpl(const ReadOptions&amp; read_options, const Slice&amp; key,</span><br><span class="line">  ...</span><br><span class="line">  SuperVersion* sv = GetAndRefSuperVersion(cfd);</span><br><span class="line">  ...</span><br><span class="line">  SequenceNumber snapshot;</span><br><span class="line">  <span class="keyword">if</span> (read_options.snapshot != nullptr) &#123;</span><br><span class="line">    <span class="keyword">if</span> (get_impl_options.callback) &#123;</span><br><span class="line">      snapshot = get_impl_options.</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      snapshot =</span><br><span class="line">          reinterpret_cast&lt;const SnapshotImpl*&gt;(read_options.snapshot)-&gt;number_;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    ....</span><br><span class="line">    snapshot = last_seq_same_as_publish_seq_</span><br><span class="line">                   ? versions_-&gt;LastSequence()</span><br><span class="line">                   : versions_-&gt;LastPublishedSequence();</span><br><span class="line">    ...</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">if</span> (!skip_memtable) &#123;</span><br><span class="line">    ...</span><br><span class="line">      <span class="keyword">if</span> (sv-&gt;mem-&gt;Get(lkey, get_impl_options.value-&gt;GetSelf(), &amp;s,</span><br><span class="line">                       &amp;merge_context, &amp;max_covering_tombstone_seq,</span><br><span class="line">                       read_options, get_impl_options.callback,</span><br><span class="line">                       get_impl_options.is_blob_index)) &#123;</span><br><span class="line">        ...</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> ((s.ok() || s.IsMergeInProgress()) &amp;&amp;</span><br><span class="line">                 sv-&gt;imm-&gt;Get(lkey, get_impl_options.value-&gt;GetSelf(), &amp;s,</span><br><span class="line">                              &amp;merge_context, &amp;max_covering_tombstone_seq,</span><br><span class="line">                              read_options, get_impl_options.callback,</span><br><span class="line">                              get_impl_options.is_blob_index)) &#123;</span><br><span class="line">        ...</span><br><span class="line">      &#125;</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (!<span class="keyword">done</span>) &#123;</span><br><span class="line">    sv-&gt;current-&gt;Get(</span><br><span class="line">        read_options, lkey, get_impl_options.value, &amp;s, &amp;merge_context,</span><br><span class="line">        &amp;max_covering_tombstone_seq,</span><br><span class="line">        get_impl_options.get_value ? get_impl_options.value_found : nullptr,</span><br><span class="line">        nullptr, nullptr,</span><br><span class="line">        get_impl_options.get_value ? get_impl_options.callback : nullptr,</span><br><span class="line">        get_impl_options.get_value ? get_impl_options.is_blob_index : nullptr,</span><br><span class="line">        get_impl_options.get_value);</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>DBImpl::GetImpl 获取 SuperVersion 的信息，如果用户未指定 snapshot，需要获取当前的 snapshot。读取时不对 key 加锁，能读到什么数据完全取决于 Options 传入的 snapshot。</p>
<p>SuperVersion 中按照数据的新旧程度排序 MemTable -&gt; MemTableListVersion -&gt; Version，依次按序查找，如果在新的数据中找到符合 snapshot 规则的结果，就可以立即返回，完成本次查找。</p>
<h3 id="MemTable-Get"><a href="#MemTable-Get" class="headerlink" title="MemTable::Get"></a>MemTable::Get</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">bool MemTable::Get(const LookupKey&amp; key, std::string* value, Status* s,</span><br><span class="line">                   MergeContext* merge_context,</span><br><span class="line">                   SequenceNumber* max_covering_tombstone_seq,</span><br><span class="line">                   SequenceNumber* seq, const ReadOptions&amp; read_opts,</span><br><span class="line">                   ReadCallback* callback, bool* is_blob_index, bool do_merge) &#123;</span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (bloom_filter_ &amp;&amp; !may_contain) &#123;</span><br><span class="line">    // iter is null <span class="keyword">if</span> prefix bloom says the key does not exist</span><br><span class="line">    PERF_COUNTER_ADD(bloom_memtable_miss_count, 1);</span><br><span class="line">    *seq = kMaxSequenceNumber;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (bloom_filter_) &#123;</span><br><span class="line">      PERF_COUNTER_ADD(bloom_memtable_hit_count, 1);</span><br><span class="line">    &#125;</span><br><span class="line">    GetFromTable(key, *max_covering_tombstone_seq, do_merge, callback,</span><br><span class="line">                 is_blob_index, value, s, merge_context, seq,</span><br><span class="line">                 &amp;found_final_value, &amp;merge_in_progress);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void MemTable::GetFromTable(const LookupKey&amp; key,</span><br><span class="line">                            SequenceNumber max_covering_tombstone_seq,</span><br><span class="line">                            bool do_merge, ReadCallback* callback,</span><br><span class="line">                            bool* is_blob_index, std::string* value, Status* s,</span><br><span class="line">                            MergeContext* merge_context, SequenceNumber* seq,</span><br><span class="line">                            bool* found_final_value, bool* merge_in_progress) &#123;</span><br><span class="line">  ...</span><br><span class="line">  table_-&gt;Get(key, &amp;saver, SaveValue);</span><br><span class="line">  *seq = saver.seq;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>利用 MemTableRep 的 Get 函数进行查找（以 SkipListRep 实现为例，在 skiplist 中进行查找，从 seek 到的位置开始向后遍历，遍历 entry 是否符合SaveValue 定义的规则）。SaveValue 函数查看当前 entry 是否还是当前查找的 key，如果不是则返回；查看当前 entry 的 snapshot 是否小于或等于需要查找的 snapshot，不符合则继续循环。如果 entry 的snapshot 符合上述条件，那么则跳出循环，返回查找结果。</p>
<h3 id="MemTableListVersion-Get"><a href="#MemTableListVersion-Get" class="headerlink" title="MemTableListVersion::Get"></a>MemTableListVersion::Get</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">bool Get(const LookupKey&amp; key, std::string* value, Status* s,</span><br><span class="line">        MergeContext* merge_context,</span><br><span class="line">        SequenceNumber* max_covering_tombstone_seq,</span><br><span class="line">        const ReadOptions&amp; read_opts, ReadCallback* callback &#x3D; nullptr,</span><br><span class="line">        bool* is_blob_index &#x3D; nullptr) &#123;</span><br><span class="line">    SequenceNumber seq;</span><br><span class="line">    return Get(key, value, s, merge_context, max_covering_tombstone_seq, &amp;seq,</span><br><span class="line">                read_opts, callback, is_blob_index);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>MemTableListVersion 用链表的形式保存了所有 Immutable memtable 的结构，查找时，按时间序依次查找于每一个 memtable，如果任何一个 memtable 查找到结果则立即返回，即返回最新的返回值。具体 memtable 查找见上述 MemTable::Get 接口。</p>
<h3 id="Version-Get"><a href="#Version-Get" class="headerlink" title="Version::Get"></a>Version::Get</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">void Version::Get(const ReadOptions&amp; read_options, const LookupKey&amp; k,</span><br><span class="line">                  PinnableSlice* value, Status* status,</span><br><span class="line">                  MergeContext* merge_context,</span><br><span class="line">                  SequenceNumber* max_covering_tombstone_seq, bool* value_found,</span><br><span class="line">                  bool* key_exists, SequenceNumber* seq, ReadCallback* callback,</span><br><span class="line">                  bool* is_blob, bool do_merge) &#123;</span><br><span class="line">  ...</span><br><span class="line">  FilePicker fp(</span><br><span class="line">      storage_info_.files_, user_key, ikey, &amp;storage_info_.level_files_brief_,</span><br><span class="line">      storage_info_.num_non_empty_levels_, &amp;storage_info_.file_indexer_,</span><br><span class="line">      user_comparator(), internal_comparator());</span><br><span class="line">  FdWithKeyRange* f &#x3D; fp.GetNextFile();</span><br><span class="line"></span><br><span class="line">  while (f !&#x3D; nullptr) &#123;</span><br><span class="line">    ...</span><br><span class="line">    *status &#x3D; table_cache_-&gt;Get(</span><br><span class="line">        read_options, *internal_comparator(), *f-&gt;file_metadata, ikey,</span><br><span class="line">        &amp;get_context, mutable_cf_options_.prefix_extractor.get(),</span><br><span class="line">        cfd_-&gt;internal_stats()-&gt;GetFileReadHist(fp.GetHitFileLevel()),</span><br><span class="line">        IsFilterSkipped(static_cast&lt;int&gt;(fp.GetHitFileLevel()),</span><br><span class="line">                        fp.IsHitFileLastInLevel()),</span><br><span class="line">        fp.GetCurrentLevel());</span><br><span class="line">    ...</span><br><span class="line">    f &#x3D; fp.GetNextFile();</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>GetNextFile 函数会遍历所有的 level，然后再遍历每个 level 的所有的文件，这里会对 level 0 的文件做一个特殊处理，这是因为只有 level 0 的 SST 的 range 不是有序的，因此我们每次查找需要查找所有的文件，也就是会一个个的遍历；而在非 level 0，我们只需要按照二分查找来得到对应的文件即可，如果二分查找不存在，那么我就需要进入下一个 level 进行查找。</p>
<p>调用 TableCache::Get 遍历单个 SST 文件，如果查找到结果立即返回。</p>
<h3 id="TableCache-Get"><a href="#TableCache-Get" class="headerlink" title="TableCache::Get"></a>TableCache::Get</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line">Status TableCache::Get(const ReadOptions&amp; options,</span><br><span class="line">                       const InternalKeyComparator&amp; internal_comparator,</span><br><span class="line">                       const FileMetaData&amp; file_meta, const Slice&amp; k,</span><br><span class="line">                       GetContext* get_context,</span><br><span class="line">                       const SliceTransform* prefix_extractor,</span><br><span class="line">                       HistogramImpl* file_read_hist, bool skip_filters,</span><br><span class="line">                       int level) &#123;</span><br><span class="line">  auto&amp; fd &#x3D; file_meta.fd;</span><br><span class="line">  std::string* row_cache_entry &#x3D; nullptr;</span><br><span class="line">  bool done &#x3D; false;</span><br><span class="line">#ifndef ROCKSDB_LITE</span><br><span class="line">  IterKey row_cache_key;</span><br><span class="line">  std::string row_cache_entry_buffer;</span><br><span class="line"></span><br><span class="line">  &#x2F;&#x2F; Check row cache if enabled. Since row cache does not currently store</span><br><span class="line">  &#x2F;&#x2F; sequence numbers, we cannot use it if we need to fetch the sequence.</span><br><span class="line">  if (ioptions_.row_cache &amp;&amp; !get_context-&gt;NeedToReadSequence()) &#123;</span><br><span class="line">    auto user_key &#x3D; ExtractUserKey(k);</span><br><span class="line">    CreateRowCacheKeyPrefix(options, fd, k, get_context, row_cache_key);</span><br><span class="line">    done &#x3D; GetFromRowCache(user_key, row_cache_key, row_cache_key.Size(),</span><br><span class="line">                           get_context);</span><br><span class="line">    if (!done) &#123;</span><br><span class="line">      row_cache_entry &#x3D; &amp;row_cache_entry_buffer;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">#endif  &#x2F;&#x2F; ROCKSDB_LITE</span><br><span class="line">  Status s;</span><br><span class="line">  TableReader* t &#x3D; fd.table_reader;</span><br><span class="line">  Cache::Handle* handle &#x3D; nullptr;</span><br><span class="line">  if (!done &amp;&amp; s.ok()) &#123;</span><br><span class="line">    if (t &#x3D;&#x3D; nullptr) &#123;</span><br><span class="line">      s &#x3D; FindTable(</span><br><span class="line">          file_options_, internal_comparator, fd, &amp;handle, prefix_extractor,</span><br><span class="line">          options.read_tier &#x3D;&#x3D; kBlockCacheTier &#x2F;* no_io *&#x2F;,</span><br><span class="line">          true &#x2F;* record_read_stats *&#x2F;, file_read_hist, skip_filters, level);</span><br><span class="line">      if (s.ok()) &#123;</span><br><span class="line">        t &#x3D; GetTableReaderFromHandle(handle);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    SequenceNumber* max_covering_tombstone_seq &#x3D;</span><br><span class="line">        get_context-&gt;max_covering_tombstone_seq();</span><br><span class="line">    if (s.ok() &amp;&amp; max_covering_tombstone_seq !&#x3D; nullptr &amp;&amp;</span><br><span class="line">        !options.ignore_range_deletions) &#123;</span><br><span class="line">      std::unique_ptr&lt;FragmentedRangeTombstoneIterator&gt; range_del_iter(</span><br><span class="line">          t-&gt;NewRangeTombstoneIterator(options));</span><br><span class="line">      if (range_del_iter !&#x3D; nullptr) &#123;</span><br><span class="line">        *max_covering_tombstone_seq &#x3D; std::max(</span><br><span class="line">            *max_covering_tombstone_seq,</span><br><span class="line">            range_del_iter-&gt;MaxCoveringTombstoneSeqnum(ExtractUserKey(k)));</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    if (s.ok()) &#123;</span><br><span class="line">      get_context-&gt;SetReplayLog(row_cache_entry);  &#x2F;&#x2F; nullptr if no cache.</span><br><span class="line">      s &#x3D; t-&gt;Get(options, k, get_context, prefix_extractor, skip_filters);</span><br><span class="line">      get_context-&gt;SetReplayLog(nullptr);</span><br><span class="line">    &#125; else if (options.read_tier &#x3D;&#x3D; kBlockCacheTier &amp;&amp; s.IsIncomplete()) &#123;</span><br><span class="line">      &#x2F;&#x2F; Couldn&#39;t find Table in cache but treat as kFound if no_io set</span><br><span class="line">      get_context-&gt;MarkKeyMayExist();</span><br><span class="line">      s &#x3D; Status::OK();</span><br><span class="line">      done &#x3D; true;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">#ifndef ROCKSDB_LITE</span><br><span class="line">  &#x2F;&#x2F; Put the replay log in row cache only if something was found.</span><br><span class="line">  if (!done &amp;&amp; s.ok() &amp;&amp; row_cache_entry &amp;&amp; !row_cache_entry-&gt;empty()) &#123;</span><br><span class="line">    size_t charge &#x3D;</span><br><span class="line">        row_cache_key.Size() + row_cache_entry-&gt;size() + sizeof(std::string);</span><br><span class="line">    void* row_ptr &#x3D; new std::string(std::move(*row_cache_entry));</span><br><span class="line">    ioptions_.row_cache-&gt;Insert(row_cache_key.GetUserKey(), row_ptr, charge,</span><br><span class="line">                                &amp;DeleteEntry&lt;std::string&gt;);</span><br><span class="line">  &#125;</span><br><span class="line">#endif  &#x2F;&#x2F; ROCKSDB_LITE</span><br><span class="line"></span><br><span class="line">  if (handle !&#x3D; nullptr) &#123;</span><br><span class="line">    ReleaseHandle(handle);</span><br><span class="line">  &#125;</span><br><span class="line">  return s;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Status TableCache::FindTable(const FileOptions&amp; file_options,</span><br><span class="line">                             const InternalKeyComparator&amp; internal_comparator,</span><br><span class="line">                             const FileDescriptor&amp; fd, Cache::Handle** handle,</span><br><span class="line">                             const SliceTransform* prefix_extractor,</span><br><span class="line">                             const bool no_io, bool record_read_stats,</span><br><span class="line">                             HistogramImpl* file_read_hist, bool skip_filters,</span><br><span class="line">                             int level,</span><br><span class="line">                             bool prefetch_index_and_filter_in_cache) &#123;</span><br><span class="line">  ...</span><br><span class="line">    std::unique_ptr&lt;TableReader&gt; table_reader;</span><br><span class="line">    s &#x3D; GetTableReader(file_options, internal_comparator, fd,</span><br><span class="line">                       false &#x2F;* sequential mode *&#x2F;, record_read_stats,</span><br><span class="line">                       file_read_hist, &amp;table_reader, prefix_extractor,</span><br><span class="line">                       skip_filters, level, prefetch_index_and_filter_in_cache);</span><br><span class="line">    if (!s.ok()) &#123;</span><br><span class="line">      assert(table_reader &#x3D;&#x3D; nullptr);</span><br><span class="line">      RecordTick(ioptions_.statistics, NO_FILE_ERRORS);</span><br><span class="line">      &#x2F;&#x2F; We do not cache error results so that if the error is transient,</span><br><span class="line">      &#x2F;&#x2F; or somebody repairs the file, we recover automatically.</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">      s &#x3D; cache_-&gt;Insert(key, table_reader.get(), 1, &amp;DeleteEntry&lt;TableReader&gt;,</span><br><span class="line">                         handle);</span><br><span class="line">      if (s.ok()) &#123;</span><br><span class="line">        &#x2F;&#x2F; Release ownership of table reader.</span><br><span class="line">        table_reader.release();</span><br><span class="line">      &#125;</span><br><span class="line">  ...</span><br><span class="line">  return s;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果 row_cache 打开，首先它会计算 row cache 的 key，再在row cache 中进行一次查找，如果有对应的值则直接返回结果，否则则将会在对应的 SST 读取传递进来的 key。</p>
<p>调用 FindTable，进行对应 table_reader 的读取以及进行 Table cache。</p>
<p>接下来调用 t-&gt;Get，从 Block cache 或者 SST 中读取数据。</p>
<p>最后，如果 row_cache 打开，把读取的数据插入到 row cache 中。</p>
<h3 id="BlockBasedTable-Get"><a href="#BlockBasedTable-Get" class="headerlink" title="BlockBasedTable::Get"></a>BlockBasedTable::Get</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">for (iiter-&gt;Seek(key); iiter-&gt;Valid()&amp;&amp;!done; iiter-&gt;Next()) &#123;</span><br><span class="line">    ...</span><br><span class="line">    NewDataBlockIterator(&amp;biter);</span><br><span class="line">    for(; biter.Valid; biter.Next()) &#123;</span><br><span class="line">        ...</span><br><span class="line">        get_context-&gt;SaveValue(biter-&gt;Value());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在 Table Cache 中，假设最终缓存的 table reader 是一个 BlockBasedTable 对象，调用 BlockBasedTable::Get。</p>
<p>首先，根据 Table 的元数据信息（布隆过滤器，数据块Index）查找 SST 内部的 Block。</p>
<p>调用 NewDataBlockIterator，若 Block 在 Block Cache 当中，直接返回对象地址，否则，发生磁盘IO，读取 SST 的 Block，构造 Block 对象并缓存其地址在 Block Cache 中。</p>
<p>找到 key 对应的 value，调用 get_context-&gt;SaveValue，直接将 Block 中的数据地址赋给用户传进来的 PinnableSlice* 中，减少了一次数据拷贝，并用引用计数避免 Block 被淘汰值被清除。</p>
<h2 id="回顾"><a href="#回顾" class="headerlink" title="回顾"></a>回顾</h2><img src="/2021/01/17/Rocksdb-Get/rocksdb_get.jpg" style="zoom:100%;">

<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><a target="_blank" rel="noopener" href="https://github.com/facebook/rocksdb/tree/v6.7.3">Rocksdb Source Code 6.7.3</a></li>
<li><a target="_blank" rel="noopener" href="https://whoiami.github.io/ROCKSDB_GET">Rocksdb Code Analysis Get</a></li>
<li><a target="_blank" rel="noopener" href="http://mysql.taobao.org/monthly/2018/12/08/">MySQL · RocksDB · 数据的读取(二)</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/30807728">使用PinnableSlice减少Get时的内存拷贝</a></li>
</ol>
</div></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/logo.jpg" alt="Iggie Wang (王亮)"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Iggie Wang (王亮)</p><p class="is-size-6 is-block">WNLO, HUST</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Wuhan, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Entradas</p><a href="/archives"><p class="title">42</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categorías</p><a href="/categories"><p class="title">0</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Etiquetas</p><a href="/tags"><p class="title">15</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/hey-kong" target="_blank" rel="noopener">SEGUIR</a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Enlaces</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://github.com/hey-kong" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li><li><a class="level is-mobile" href="iggiewang@gmail.com" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Email</span></span><span class="level-right"><span class="level-item tag">iggiewang@gmail.com</span></span></a></li></ul></div></div></div><!--!--><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archivos</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2023/08/"><span class="level-start"><span class="level-item">August 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/07/"><span class="level-start"><span class="level-item">July 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/12/"><span class="level-start"><span class="level-item">December 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/06/"><span class="level-start"><span class="level-item">June 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/05/"><span class="level-start"><span class="level-item">May 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/03/"><span class="level-start"><span class="level-item">March 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/02/"><span class="level-start"><span class="level-item">February 2022</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/01/"><span class="level-start"><span class="level-item">January 2022</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/10/"><span class="level-start"><span class="level-item">October 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/09/"><span class="level-start"><span class="level-item">September 2021</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/08/"><span class="level-start"><span class="level-item">August 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/07/"><span class="level-start"><span class="level-item">July 2021</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/05/"><span class="level-start"><span class="level-item">May 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/04/"><span class="level-start"><span class="level-item">April 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/03/"><span class="level-start"><span class="level-item">March 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/02/"><span class="level-start"><span class="level-item">February 2021</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/01/"><span class="level-start"><span class="level-item">January 2021</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Etiquetas</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/CSAPP/"><span class="tag">CSAPP</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Cache/"><span class="tag">Cache</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Chinese/"><span class="tag">Chinese</span><span class="tag">37</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Database/"><span class="tag">Database</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Edge-computing/"><span class="tag">Edge computing</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/English/"><span class="tag">English</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/File-System/"><span class="tag">File System</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Key-Value-Store/"><span class="tag">Key-Value Store</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/KubeEdge/"><span class="tag">KubeEdge</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Learned-Index/"><span class="tag">Learned Index</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RDMA/"><span class="tag">RDMA</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Rocksdb/"><span class="tag">Rocksdb</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/docker/"><span class="tag">docker</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/etcd/"><span class="tag">etcd</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/k8s/"><span class="tag">k8s</span><span class="tag">4</span></a></div></div></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">Iggie Wang&#039;s Cyberspace</a><p class="is-size-7"><span>&copy; 2023 王亮</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdnjs.loli.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" defer></script><script>moment.locale("default");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Volver arriba" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/cookieconsent/3.1.1/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "Este sitio web utiliza cookies para mejorar su experiencia.",
          dismiss: "¡Entendido!",
          allow: "Permitir cookies",
          deny: "Descenso",
          link: "Aprende más",
          policy: "Política de cookies",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/js/lightgallery.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdnjs.loli.net/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Teclea algo..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Teclea algo...","untitled":"(Sin título)","posts":"Entradas","pages":"Páginas","categories":"Categorías","tags":"Etiquetas"});
        });</script></body></html>